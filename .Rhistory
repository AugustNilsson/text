group2 <- x2 %>%
dplyr::filter(value > mean(purrr::as_vector(value), na.rm = TRUE))
# Use function addEqualNrNArows from 3_1_testSimilarity
# Function adds rows of NA until group2 and group1 have the same amount of rows.
if (nrow(group1) < nrow(group2)) {
group1 <- addEqualNrNArows(group1, group2)
} else if (nrow(group1) > nrow(group2)) {
group2 <- addEqualNrNArows(group2, group1)
} else {
group1 <- group1
group2 <- group2
}
##########
####        Get word embeddings
##########
# Group 1: getting unique words and their frequency
words_group1b_freq <- unique_freq_words(group1$words)
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_wordembeddings)
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_wordembeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
# All: Group 1 & 2
#words_group1_2_freq <- unique_freq_words(x2$words)
#words_group1_2_freq_b <- words_group1_2_freq[words_group1_2_freq$n >= min_freq_words, ]
#words_group1_2_freq_b <- dplyr::rename(words_group1_2_freq_b, n_all = n)
#words_group1_2_single_wordembedding <- lapply(words_group1_2_freq_b$words, applysemrep, single_wordembeddings)
############
######         1 Create COMPARISON/Projection embedding: all Group 1 & Group 2 word embeddings.
############
### Sum all word embeddings in one column
# split="median" split = "quartile"
if (split == "mean") {
words_group1_agg_single_wordembedding_c <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group2_agg_single_wordembedding_c <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
} else if (split == "quartile") {
# Select according to lower and upper quartile
# However, if it is a dichotomous variable use mean
if(length(unique(x1$value)) == 2){
q1 <- summary(x1$value)[4][[1]]
q3 <- summary(x1$value)[4][[1]]
}else if(length(unique(x1$value)) > 2){
q1 <- summary(x1$value)[2][[1]]
q3 <- summary(x1$value)[5][[1]]
}
group1_agg <- x2 %>%
dplyr::filter(x2$value < q1, )
group2_agg <- x2 %>%
dplyr::filter(x2$value > q3, )
words_group1_agg_freq <- unique_freq_words(group1_agg$words)
words_group1_agg_freq1 <- words_group1_agg_freq[words_group1_agg_freq$n >= min_freq_words, ]
words_group1_agg_single_wordembedding <- lapply(words_group1_agg_freq1$words, applysemrep, single_wordembeddings)
words_group1_agg_single_wordembedding_b <- dplyr::bind_rows(words_group1_agg_single_wordembedding)
words_group1_agg_single_wordembedding_c <- cbind(words_group1_agg_freq1, words_group1_agg_single_wordembedding_b)
words_group2_agg_freq <- unique_freq_words(group2_agg$words)
words_group2_agg_freq1 <- words_group2_agg_freq[words_group2_agg_freq$n >= min_freq_words, ]
words_group2_agg_single_wordembedding <- lapply(words_group2_agg_freq1$words, applysemrep, single_wordembeddings)
words_group2_agg_single_wordembedding_b <- dplyr::bind_rows(words_group2_agg_single_wordembedding)
words_group2_agg_single_wordembedding_c <- cbind(words_group2_agg_freq1, words_group2_agg_single_wordembedding_b)
}
words_group1_agg_single_wordembedding_c <- tibble::as_tibble(words_group1_agg_single_wordembedding_c)
words_group2_agg_single_wordembedding_c <- tibble::as_tibble(words_group2_agg_single_wordembedding_c)
# Weight words for aggregated word embedding: Repeat rows according to n word_weight_power
words_group1_agg_single_wordembedding_d <- words_group1_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
words_group2_agg_single_wordembedding_d <- words_group2_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
Aggregated_word_embedding_group1 <- textEmbeddingAggregation(dplyr::select(words_group1_agg_single_wordembedding_d, dplyr::starts_with("Dim")), aggregation = aggregation)
Aggregated_word_embedding_group2 <- textEmbeddingAggregation(dplyr::select(words_group2_agg_single_wordembedding_d, dplyr::starts_with("Dim")), aggregation = aggregation)
############
######         Project embedding
#############
projected_embedding <- Aggregated_word_embedding_group2 - Aggregated_word_embedding_group1
# Position words in relation to Group 2 (High)
all_unique_words_freq <- unique_freq_words(x2$words)
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
all_unique_words_we <- lapply(all_unique_words_freq$words, applysemrep, single_wordembeddings)
all_unique_words_we_b <- dplyr::bind_rows(all_unique_words_we)
# Position the embedding; i.e., taking the word embedding substracted with aggregated word embedding
# version 1: word_new = word_old - ((group(high harmony) + group(low harmony)) / 2)
words_positioned_embeddings <- all_unique_words_we_b - ((t(replicate(nrow(all_unique_words_we_b), Aggregated_word_embedding_group2)) +
t(replicate(nrow(all_unique_words_we_b), Aggregated_word_embedding_group1))) / 2)
# Project the embeddings using dot product.
dot_products_observed <- rowSums(words_positioned_embeddings * t(replicate(nrow(all_unique_words_we_b), projected_embedding)))
all_unique_words_freq$dot <- dot_products_observed
############
######         Comparison distributions for Project embedding
#############
# Get dataframe with ALL embedding to randomly draw from (without log transformed, and quartiles)
words_group1_agg_single_wordembedding_e <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group1_agg_single_wordembedding_f <- words_group1_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group2_agg_single_wordembedding_e <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group2_agg_single_wordembedding_f <- words_group2_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group1_2_agg_single_wordembedding_e <- rbind(words_group1_agg_single_wordembedding_f, words_group2_agg_single_wordembedding_f)
words_group1_2_agg_single_wordembedding_e1 <- dplyr::select(words_group1_2_agg_single_wordembedding_e, dplyr::starts_with("Dim"))
# Splitting up the permutations in different loops to avoid memory issues
forloops <- ceiling(Npermutations / n_per_split)
dot_null_distribution <- list()
# i=1
for (i in 1:forloops) {
### Create new Projected embedding
# Randomly split word embeddings into two groups: words_group1_2_agg_single_wordembedding_e1
ind <- sample(c(TRUE, FALSE), nrow(words_group1_2_agg_single_wordembedding_e1), replace = TRUE)
Aggregated_word_embedding_group1_random <- words_group1_2_agg_single_wordembedding_e1[ind, ]
Aggregated_word_embedding_group1_random <- textEmbeddingAggregation(Aggregated_word_embedding_group1_random, aggregation = "mean")
Aggregated_word_embedding_group2_random <- words_group1_2_agg_single_wordembedding_e1[!ind, ]
Aggregated_word_embedding_group2_random <- textEmbeddingAggregation(Aggregated_word_embedding_group2_random, aggregation = "mean")
projected_embedding_random <- Aggregated_word_embedding_group2_random - Aggregated_word_embedding_group1_random
# Select random word embeddings according to setting
indice <- sample(nrow(words_group1_2_agg_single_wordembedding_e1), n_per_split, replace = TRUE)
random_group2_embedding <- words_group1_2_agg_single_wordembedding_e1[indice, ]
# Position the embedding; i.e., taking the word embedding subtracted with aggregated word embedding
# version 1: word_new = word_old - ((group(high harmony) + group(low harmony)) / 2)
words_positioned_embeddings_random <- random_group2_embedding - ((t(replicate(nrow(random_group2_embedding), Aggregated_word_embedding_group2)) +
t(replicate(nrow(random_group2_embedding), Aggregated_word_embedding_group1))) / 2)
# project the embeddings using dot products
dot_products_null <- as_tibble(rowSums(words_positioned_embeddings_random * t(replicate(nrow(words_positioned_embeddings_random), projected_embedding_random))))
dot_null_distribution[i] <- dot_products_null
dot_null_distribution
}
dot_null_distribution <- tibble::as_tibble(unlist(dot_null_distribution))
### Compare observed dot-product with null
dot_null_distribution <- dot_null_distribution[stats::complete.cases(dot_null_distribution), ]
p_values_dot_prod <- purrr::map(as.list(purrr::as_vector(dot_products_observed)), p_value_comparing_with_Null,
dot_null_distribution,
Npermutations = Npermutations, alternative = "two_sided"
)
p_values_dot_prod <- unlist(p_values_dot_prod)
# Sort out dataframe
dot_result <- cbind(all_unique_words_freq, dot_products_observed, tibble::as_tibble(unlist(p_values_dot_prod)))
dot_result <- tibble::as_tibble(dot_result)
colnames(dot_result) <- c("words", "n", "dot", "dot2", "p_values_dot")
dot_result <- dplyr::select(dot_result, -c(dot2))
words_group2b_freq <- dplyr::select(words_group2b_freq, -c(n))
words_group1b_freq <- dplyr::select(words_group1b_freq, -c(n))
dot_result1 <- dplyr::full_join(dot_result, words_group1b_freq, by = "words")
dot_result2 <- dplyr::full_join(dot_result1, words_group2b_freq, by = "words")
dot_result <- tibble::as_tibble(dot_result2)
colnames(dot_result) <- c("words", "n", "dot", "p_values_dot", "n_g1", "n_g2")
word_data_list[i_dim] <- list(dot_result)
}
words <- c("words", "text", "hello", "-", "-")
words_group1 <- data.frame(unlist(strsplit(tolower(words), " ")))
# Remove empty cells (otherwise all words are put within " ", which create problems in getUniqueWordsAndFreq or textCentralityData)
words_group <- words_group1[words_group1 != ""]
words_group <- as.character(words_group)
words_groupb <- tibble::as_tibble(words_group)
sort(words_groupb$value)
words_groupb <- table(words_groupb)
words_groupb
words_groupb_freq <- tibble::as_tibble(words_groupb, .name_repair = make.names)
words_groupb_freq
#' Takes all words as input and arrange them in column with an accompanying column with frequency.
#' @param words Words
#' @return Column with all words and an accompanying column with their frequency.
#' @importFrom tibble as_tibble
#' @noRd
unique_freq_words <- function(words) {
words_group1 <- data.frame(unlist(strsplit(tolower(words), " ")))
# Remove empty cells (otherwise all words are put within " ", which create problems in getUniqueWordsAndFreq or textCentralityData)
words_group <- words_group1[words_group1 != ""]
words_group <- as.character(words_group)
words_groupb <- tibble::as_tibble(words_group)
sort(words_groupb$value)
words_groupb <- table(words_groupb)
words_groupb_freq <- tibble::as_tibble(words_groupb, .name_repair = make.names)
colnames(words_groupb_freq) <- c("words", "n")
words_groupb_freq
}
words = dataok1$Words_momentaryH
x = dataok1$GSDG_Cooperation
y = dataok1$Receive2
#' Takes all words as input and arrange them in column with an accompanying column with frequency.
#' @param words Words
#' @return Column with all words and an accompanying column with their frequency.
#' @importFrom tibble as_tibble
#' @noRd
unique_freq_words <- function(words) {
words_group1 <- data.frame(unlist(strsplit(tolower(words), " ")))
# Remove empty cells (otherwise all words are put within " ", which create problems in getUniqueWordsAndFreq or textCentralityData)
words_group <- words_group1[words_group1 != ""]
words_group <- as.character(words_group)
words_groupb <- tibble::as_tibble(words_group)
sort(words_groupb$value)
words_groupb <- table(words_groupb)
words_groupb_freq <- tibble::as_tibble(words_groupb, .name_repair = make.names)
colnames(words_groupb_freq) <- c("words", "n")
words_groupb_freq
}
set.seed(2020)
# PCA on single_wordembeddings
if (is.numeric(pca)) {
# Select word embeddings to be included in plot
uniques_words_all <- unique_freq_words(words)
uniques_words_all_wordembedding <- sapply(uniques_words_all$words, applysemrep, single_wordembeddings)
uniques_words_all_wordembedding <- tibble::as_tibble(t(uniques_words_all_wordembedding))
rec_pca <- recipes::recipe(~., data = uniques_words_all_wordembedding)
pca_trans <- rec_pca %>%
recipes::step_center(recipes::all_numeric()) %>%
recipes::step_scale(recipes::all_numeric()) %>%
recipes::step_naomit(Dim1, skip = TRUE)
if (pca < 1) { #pca=0.9
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), threshold = pca)
} else if (pca >= 1) {
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), num_comp = pca)
}
pca_estimates <- recipes::prep(pca_trans, training = uniques_words_all_wordembedding)
pca_data <- recipes::bake(pca_estimates, uniques_words_all_wordembedding)
pca_data <- pca_data %>% stats::setNames(paste0("Dim_", names(.)))
single_wordembeddings <- dplyr::bind_cols(uniques_words_all, pca_data)
single_wordembeddings
}
# Make dataframe (and combine x and y)
if (is.null(y)) {
x <- tibble::as_tibble_col(x)
} else {
# Combine the dimensions for for-loop
x <- tibble::tibble(x, y)
}
# Creating a list for the x and y dimensions
word_data_list <- list()
# For-loop for x and y input/dimensions; i.e., y if the plot has two dimensions (i_dim=1 i_dim=2) remove(i_dim)
for (i_dim in seq_len(ncol(x))) {
# Get the word embeddings and scale/category for the plot dimension (i.e., x or y from above)
x0 <- x[i_dim]
x1 <- cbind(words, x0)
colnames(x1) <- c("words", "value")
x2 <- tibble::as_tibble(cbind(x1, wordembeddings))
# Splitting datasets up to low versus high according to median split
#group1 <- x2[x2[2] < stats::median(purrr::as_vector(x2$value), na.rm = TRUE), ]
#group2 <- x2[x2[2] > stats::median(purrr::as_vector(x2$value), na.rm = TRUE), ]
group1 <- x2 %>%
dplyr::filter(value < mean(purrr::as_vector(value), na.rm = TRUE))
group2 <- x2 %>%
dplyr::filter(value > mean(purrr::as_vector(value), na.rm = TRUE))
# Use function addEqualNrNArows from 3_1_testSimilarity
# Function adds rows of NA until group2 and group1 have the same amount of rows.
if (nrow(group1) < nrow(group2)) {
group1 <- addEqualNrNArows(group1, group2)
} else if (nrow(group1) > nrow(group2)) {
group2 <- addEqualNrNArows(group2, group1)
} else {
group1 <- group1
group2 <- group2
}
##########
####        Get word embeddings
##########
# Group 1: getting unique words and their frequency
words_group1b_freq <- unique_freq_words(group1$words)
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_wordembeddings)
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_wordembeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
# All: Group 1 & 2
#words_group1_2_freq <- unique_freq_words(x2$words)
#words_group1_2_freq_b <- words_group1_2_freq[words_group1_2_freq$n >= min_freq_words, ]
#words_group1_2_freq_b <- dplyr::rename(words_group1_2_freq_b, n_all = n)
#words_group1_2_single_wordembedding <- lapply(words_group1_2_freq_b$words, applysemrep, single_wordembeddings)
############
######         1 Create COMPARISON/Projection embedding: all Group 1 & Group 2 word embeddings.
############
### Sum all word embeddings in one column
# split="median" split = "quartile"
if (split == "mean") {
words_group1_agg_single_wordembedding_c <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group2_agg_single_wordembedding_c <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
} else if (split == "quartile") {
# Select according to lower and upper quartile
# However, if it is a dichotomous variable use mean
if(length(unique(x1$value)) == 2){
q1 <- summary(x1$value)[4][[1]]
q3 <- summary(x1$value)[4][[1]]
}else if(length(unique(x1$value)) > 2){
q1 <- summary(x1$value)[2][[1]]
q3 <- summary(x1$value)[5][[1]]
}
group1_agg <- x2 %>%
dplyr::filter(x2$value < q1, )
group2_agg <- x2 %>%
dplyr::filter(x2$value > q3, )
words_group1_agg_freq <- unique_freq_words(group1_agg$words)
words_group1_agg_freq1 <- words_group1_agg_freq[words_group1_agg_freq$n >= min_freq_words, ]
words_group1_agg_single_wordembedding <- lapply(words_group1_agg_freq1$words, applysemrep, single_wordembeddings)
words_group1_agg_single_wordembedding_b <- dplyr::bind_rows(words_group1_agg_single_wordembedding)
words_group1_agg_single_wordembedding_c <- cbind(words_group1_agg_freq1, words_group1_agg_single_wordembedding_b)
words_group2_agg_freq <- unique_freq_words(group2_agg$words)
words_group2_agg_freq1 <- words_group2_agg_freq[words_group2_agg_freq$n >= min_freq_words, ]
words_group2_agg_single_wordembedding <- lapply(words_group2_agg_freq1$words, applysemrep, single_wordembeddings)
words_group2_agg_single_wordembedding_b <- dplyr::bind_rows(words_group2_agg_single_wordembedding)
words_group2_agg_single_wordembedding_c <- cbind(words_group2_agg_freq1, words_group2_agg_single_wordembedding_b)
}
words_group1_agg_single_wordembedding_c <- tibble::as_tibble(words_group1_agg_single_wordembedding_c)
words_group2_agg_single_wordembedding_c <- tibble::as_tibble(words_group2_agg_single_wordembedding_c)
# Weight words for aggregated word embedding: Repeat rows according to n word_weight_power
words_group1_agg_single_wordembedding_d <- words_group1_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
words_group2_agg_single_wordembedding_d <- words_group2_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
Aggregated_word_embedding_group1 <- textEmbeddingAggregation(dplyr::select(words_group1_agg_single_wordembedding_d, dplyr::starts_with("Dim")), aggregation = aggregation)
Aggregated_word_embedding_group2 <- textEmbeddingAggregation(dplyr::select(words_group2_agg_single_wordembedding_d, dplyr::starts_with("Dim")), aggregation = aggregation)
############
######         Project embedding
#############
projected_embedding <- Aggregated_word_embedding_group2 - Aggregated_word_embedding_group1
# Position words in relation to Group 2 (High)
all_unique_words_freq <- unique_freq_words(x2$words)
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
all_unique_words_we <- lapply(all_unique_words_freq$words, applysemrep, single_wordembeddings)
all_unique_words_we_b <- dplyr::bind_rows(all_unique_words_we)
# Position the embedding; i.e., taking the word embedding substracted with aggregated word embedding
# version 1: word_new = word_old - ((group(high harmony) + group(low harmony)) / 2)
words_positioned_embeddings <- all_unique_words_we_b - ((t(replicate(nrow(all_unique_words_we_b), Aggregated_word_embedding_group2)) +
t(replicate(nrow(all_unique_words_we_b), Aggregated_word_embedding_group1))) / 2)
# Project the embeddings using dot product.
dot_products_observed <- rowSums(words_positioned_embeddings * t(replicate(nrow(all_unique_words_we_b), projected_embedding)))
all_unique_words_freq$dot <- dot_products_observed
############
######         Comparison distributions for Project embedding
#############
# Get dataframe with ALL embedding to randomly draw from (without log transformed, and quartiles)
words_group1_agg_single_wordembedding_e <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group1_agg_single_wordembedding_f <- words_group1_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group2_agg_single_wordembedding_e <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group2_agg_single_wordembedding_f <- words_group2_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group1_2_agg_single_wordembedding_e <- rbind(words_group1_agg_single_wordembedding_f, words_group2_agg_single_wordembedding_f)
words_group1_2_agg_single_wordembedding_e1 <- dplyr::select(words_group1_2_agg_single_wordembedding_e, dplyr::starts_with("Dim"))
# Splitting up the permutations in different loops to avoid memory issues
forloops <- ceiling(Npermutations / n_per_split)
dot_null_distribution <- list()
# i=1
for (i in 1:forloops) {
### Create new Projected embedding
# Randomly split word embeddings into two groups: words_group1_2_agg_single_wordembedding_e1
ind <- sample(c(TRUE, FALSE), nrow(words_group1_2_agg_single_wordembedding_e1), replace = TRUE)
Aggregated_word_embedding_group1_random <- words_group1_2_agg_single_wordembedding_e1[ind, ]
Aggregated_word_embedding_group1_random <- textEmbeddingAggregation(Aggregated_word_embedding_group1_random, aggregation = "mean")
Aggregated_word_embedding_group2_random <- words_group1_2_agg_single_wordembedding_e1[!ind, ]
Aggregated_word_embedding_group2_random <- textEmbeddingAggregation(Aggregated_word_embedding_group2_random, aggregation = "mean")
projected_embedding_random <- Aggregated_word_embedding_group2_random - Aggregated_word_embedding_group1_random
# Select random word embeddings according to setting
indice <- sample(nrow(words_group1_2_agg_single_wordembedding_e1), n_per_split, replace = TRUE)
random_group2_embedding <- words_group1_2_agg_single_wordembedding_e1[indice, ]
# Position the embedding; i.e., taking the word embedding subtracted with aggregated word embedding
# version 1: word_new = word_old - ((group(high harmony) + group(low harmony)) / 2)
words_positioned_embeddings_random <- random_group2_embedding - ((t(replicate(nrow(random_group2_embedding), Aggregated_word_embedding_group2)) +
t(replicate(nrow(random_group2_embedding), Aggregated_word_embedding_group1))) / 2)
# project the embeddings using dot products
dot_products_null <- as_tibble(rowSums(words_positioned_embeddings_random * t(replicate(nrow(words_positioned_embeddings_random), projected_embedding_random))))
dot_null_distribution[i] <- dot_products_null
dot_null_distribution
}
dot_null_distribution <- tibble::as_tibble(unlist(dot_null_distribution))
### Compare observed dot-product with null
dot_null_distribution <- dot_null_distribution[stats::complete.cases(dot_null_distribution), ]
p_values_dot_prod <- purrr::map(as.list(purrr::as_vector(dot_products_observed)), p_value_comparing_with_Null,
dot_null_distribution,
Npermutations = Npermutations, alternative = "two_sided"
)
p_values_dot_prod <- unlist(p_values_dot_prod)
# Sort out dataframe
dot_result <- cbind(all_unique_words_freq, dot_products_observed, tibble::as_tibble(unlist(p_values_dot_prod)))
dot_result <- tibble::as_tibble(dot_result)
colnames(dot_result) <- c("words", "n", "dot", "dot2", "p_values_dot")
dot_result <- dplyr::select(dot_result, -c(dot2))
words_group2b_freq <- dplyr::select(words_group2b_freq, -c(n))
words_group1b_freq <- dplyr::select(words_group1b_freq, -c(n))
dot_result1 <- dplyr::full_join(dot_result, words_group1b_freq, by = "words")
dot_result2 <- dplyr::full_join(dot_result1, words_group2b_freq, by = "words")
dot_result <- tibble::as_tibble(dot_result2)
colnames(dot_result) <- c("words", "n", "dot", "p_values_dot", "n_g1", "n_g2")
word_data_list[i_dim] <- list(dot_result)
}
y = dataok1$Receive2
x = dataok1$GSDG_Cooperation
words = dataok1$Words_momentaryH
set.seed(2020)
# PCA on single_wordembeddings
if (is.numeric(pca)) {
# Select word embeddings to be included in plot
uniques_words_all <- unique_freq_words(words)
uniques_words_all_wordembedding <- sapply(uniques_words_all$words, applysemrep, single_wordembeddings)
uniques_words_all_wordembedding <- tibble::as_tibble(t(uniques_words_all_wordembedding))
rec_pca <- recipes::recipe(~., data = uniques_words_all_wordembedding)
pca_trans <- rec_pca %>%
recipes::step_center(recipes::all_numeric()) %>%
recipes::step_scale(recipes::all_numeric()) %>%
recipes::step_naomit(Dim1, skip = TRUE)
if (pca < 1) { #pca=0.9
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), threshold = pca)
} else if (pca >= 1) {
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), num_comp = pca)
}
pca_estimates <- recipes::prep(pca_trans, training = uniques_words_all_wordembedding)
pca_data <- recipes::bake(pca_estimates, uniques_words_all_wordembedding)
pca_data <- pca_data %>% stats::setNames(paste0("Dim_", names(.)))
single_wordembeddings <- dplyr::bind_cols(uniques_words_all, pca_data)
single_wordembeddings
}
# Make dataframe (and combine x and y)
if (is.null(y)) {
x <- tibble::as_tibble_col(x)
} else {
# Combine the dimensions for for-loop
x <- tibble::tibble(x, y)
}
# Creating a list for the x and y dimensions
word_data_list <- list()
i_dim=1
# Get the word embeddings and scale/category for the plot dimension (i.e., x or y from above)
x0 <- x[i_dim]
x0
x1 <- cbind(words, x0)
colnames(x1) <- c("words", "value")
x1
x2 <- tibble::as_tibble(cbind(x1, wordembeddings))
# Splitting datasets up to low versus high according to median split
#group1 <- x2[x2[2] < stats::median(purrr::as_vector(x2$value), na.rm = TRUE), ]
#group2 <- x2[x2[2] > stats::median(purrr::as_vector(x2$value), na.rm = TRUE), ]
group1 <- x2 %>%
dplyr::filter(value < mean(purrr::as_vector(value), na.rm = TRUE))
group2 <- x2 %>%
dplyr::filter(value > mean(purrr::as_vector(value), na.rm = TRUE))
group1
group2
# Use function addEqualNrNArows from 3_1_testSimilarity
# Function adds rows of NA until group2 and group1 have the same amount of rows.
if (nrow(group1) < nrow(group2)) {
group1 <- addEqualNrNArows(group1, group2)
} else if (nrow(group1) > nrow(group2)) {
group2 <- addEqualNrNArows(group2, group1)
} else {
group1 <- group1
group2 <- group2
}
group1
group2
##########
####        Get word embeddings
##########
# Group 1: getting unique words and their frequency
words_group1b_freq <- unique_freq_words(group1$words)
words_group1b_freq
group1$words
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_wordembeddings)
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
group2$words
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_wordembeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
# Select according to lower and upper quartile
# However, if it is a dichotomous variable use mean
if(length(unique(x1$value)) == 2){
q1 <- summary(x1$value)[4][[1]]
q3 <- summary(x1$value)[4][[1]]
}else if(length(unique(x1$value)) > 2){
q1 <- summary(x1$value)[2][[1]]
q3 <- summary(x1$value)[5][[1]]
}
q1
q3
group1_agg <- x2 %>%
dplyr::filter(x2$value < q1, )
group1_agg
group2_agg <- x2 %>%
dplyr::filter(x2$value > q3, )
group2_agg
words_group1_agg_freq <- unique_freq_words(group1_agg$words)
x1
unique(x1$value)) == 2
length(unique(x1$value)) == 2
summary(x1$value)
group1_agg <- x2 %>%
dplyr::filter(x2$value <= q1, )
group2_agg <- x2 %>%
dplyr::filter(x2$value >= q3, )
group1_agg
group2_agg
devtools::document()
