legend.justification = c("right", "top"),
panel.grid.major = ggplot2::element_blank(),
panel.grid.minor = ggplot2::element_blank(),
axis.text.y = y_axes_values,
title = ggplot2::element_text(color = titles_color),
axis.title.x = ggplot2::element_text(color = titles_color),
axis.title.y = ggplot2::element_text(color = titles_color)
)
plot
# Dot Product Projection Plot
plot_projection <- textProjectionPlot(
plot_projection <- textProjectionPlot(
word_data = DP_projections_HILS_SWLS_100,
k_n_words_two_test = FALSE,
min_freq_words = 1,
plot_n_words_square = 3,
plot_n_words_p = 3,
plot_n_word_extreme = 1,
plot_n_word_frequency = 1,
plot_n_words_middle = 1,
x_axes = TRUE,
y_axes = FALSE,
p_alpha = 0.05,
title_top = " Dot Product Projection (DPP)",
x_axes_label = "Low vs. High HILS score",
y_axes_label = "Low vs. High SWLS score",
p_adjust_method = "bonferroni",
scale_y_axes_lim = NULL
)
plot_projection
devtools::document()
devtools::document()
library(text)
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
centrality_plot
devtools::document()
library(text)
devtools::document()
library(text)
devtools::install_github("OscarKjell/text", auth_token = "99a9388f1ef7a1e44b94f3650d9aeb7ea0658bea")
x <- Language_based_assessment_data_8_10[1:2, 1:2]
wordembeddings <- textHuggingFace(x, layers = 'all')
pkgdown::build_site()
wordembeddings_1c
wordembeddings_1c <- textHuggingFace(x, layers = 'all', model = "bert-base-multilingual-cased")
wordembeddings_1c
wordembeddings_1c[[1]][[1]]
wordembeddings_1c[[1]][[1]][[1]]
wordembeddings_1c[[1]][[1]][[1]]$layer_number
wordembeddings_10b <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-large")
wordembeddings_10b
wordembeddings_10b[[1]][[1]][[1]]$layer_number
wordembeddings_10b[[1]][[1]][[1]]
wordembeddings_9 <- textHuggingFace(x, layers = 'all', model = "roberta-base")
wordembeddings_9[[1]][[1]][[1]]$layer_number
wordembeddings_9[[1]][[1]][[1]]
help("textProjectionPlot")
devtools::document()
pkgdown::build_site()
help("textHuggingFace")
textHuggingFace(
x,
contexts = TRUE,
decontexts = TRUE,
model = NULL,
layers = 11:12,
return_tokens = TRUE,
pretrained_weights = 't5-small',
tokenizer_class = T5Tokenizer,
model_class = T5Model
)
x
textHuggingFace(
x,
contexts = TRUE,
decontexts = TRUE,
model = NULL,
layers = '11:12',
return_tokens = TRUE,
pretrained_weights = 't5-small',
tokenizer_class = T5Tokenizer,
model_class = T5Model
)
model = NULL
pretrained_weights = 't5-small'
tokenizer_class = T5Tokenizer
# Run python file with HunggingFace interface to state-of-the-art transformers UPDATING
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("python", "huggingface_Interface3.py", package="text", mustWork = TRUE))
View(ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP)
model
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
}
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (is.null(model)){
pretrained_weights
tokenizer_class
model_class
}
is.null(model)
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (is.null(model)==TRUE){
pretrained_weights
tokenizer_class
model_class
}
is.null(model)
model
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (is.null(model) == TRUE){
pretrained_weights
tokenizer_class
model_class
}
model = "NULL"
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "NULL"){
pretrained_weights
tokenizer_class
model_class
}
pretrained_weights
tokenizer_class
tokenizer_class = T5Tokenizer
model_class = T5Model
model
model = "new"
model
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "xlm-roberta-large"){
pretrained_weights = 'xlm-roberta-large'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
} else if (model == "new"){
pretrained_weights
tokenizer_class
model_class
}
library(text)
textHuggingFace(
x,
contexts = TRUE,
decontexts = TRUE,
model = "new",
layers = '11:12',
return_tokens = TRUE,
pretrained_weights = 't5-small',
tokenizer_class = T5Tokenizer,
model_class = T5Model
)
.rs.restartR()
library(text)
wordembeddings_11 <- textHuggingFace(
x,
contexts = TRUE,
decontexts = TRUE,
model = "new",
layers = '11:12',
return_tokens = TRUE,
pretrained_weights = 't5-small',
tokenizer_class = T5Tokenizer,
model_class = T5Model
)
wordembeddings_10b <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-large")
wordembeddings_10b
.rs.restartR()
library(text)
wordembeddings_11 <- textHuggingFace(
x,
contexts = TRUE,
decontexts = TRUE,
model = "new",
layers = '11:12',
return_tokens = TRUE,
pretrained_weights = 't5-small',
tokenizer_class = T5Tokenizer,
model_class = T5Model
)
wordembeddings_10b <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-large")
x <- Language_based_assessment_data_8_10[1, 1]
wordembeddings_10b <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-large")
library(text)
wordembeddings_11 <- textHuggingFace(x, layers = 'all', model = "t5-small")
wordembeddings_11 <- textHuggingFace(x, layers = 'all', model = "t5-small")
devtools::document()
pkgdown::build_site()
devtools::document()
