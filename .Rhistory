y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 11:12,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 'all',  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
y12  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 11:12,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y12
y1
y12
equal(y1, y12)
identical(y1, y12)
y12  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10:11,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y12
identical(y1, y12)
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
x  <-  "I am here"
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 'all',  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
y12  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 10:11,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y12
identical(y1, y12)
y12  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 9,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y12
identical(y1, y12)
#You can download R and R-studio for free
#This cript includes code for combing word respoenss for semantic questions, adding rating scales items together,
#computing Cronbach's alpha and McDonald's omega, correlations, and saving the data to a file that can be importarted to Semantic Excel
#If something does not work, try to first Google for a solution as there are great resources online and it is very improtant to learn how to find this infomration when working in R
#This sets your working directory; that is, the folder that you work in.
#So on your computer, create a folder and add your raw data files in it. Then copy and past the path to the folder below.
setwd("/Users/amaliaadnanes/Desktop/Creativity at word RAW DATA/")
setwd("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/Creativity at word RAW DATA/")
#First time you open a libray you may eed to install it on your computer. So remove the # sign below and run the installation code line; then run the library line after installation. If you close down R you only need to run the library code again
#install.packages("tidyverse")
library(tidyverse)
#Open rest of libraries (install them as needed)
library(car)
library(psych)
#install.packages("car")
#install.packages("psych")
# Load your data-file
data_C1 <- read.csv(file="CREATIVITY_1_survey_516424_SPSS_data_file.csv", sep = ",", dec = ".", header=TRUE)
head(data_C1)
nrow(data_C1)
#Adding a column indicating which class/group they are in
data_C1$Group_Class <- c(rep(1, nrow(data_C1)))
data_C1$Group_Class
head(data_C1)
nrow(data_C1)
data_C2 <- read.csv(file="CREATIVITY_2_survey_916984_SPSS_data_file.csv", sep = ",", dec = ".", header=TRUE)
nrow(data_C2)
#Adding a column indicating which class/group they are in
data_C2$Group_Class <- c(rep(0, nrow(data_C2)))
data_C2$Group_Class
head(data_C2)
nrow(data_C2)
#merge the two files
data <- rbind(data_C1, data_C2)
nrow(data)
#Remove not-submitted responses; that is, remove those rows that do not have anythinig in the submitdate column
ds <- data[!(data$submitdate==" "), ]
nrow(ds)
#Change name of the ID column to participant_id; That is, is it called ID in the dataset from limesurvey? Otherwise change "ID" below to the name it has in the ds dataframe.
colnames(ds)[which(names(ds) == "WorkerID")] <- "participant_id"
ds$participant_id
#Read Prolificdata
#5ceb = ASDFASDFASDFAFs
prolific_1 <- read.csv("CREATIVITY_1_prolific_export_5dde86255daaa6ddfafa4624.csv")
prolific_2 <- read.csv("CREATIVITY_2_prolific_export_5dde89487af661e01eab04f4.csv")
prolific <- rbind(prolific_1, prolific_2)
head(prolific)
nrow(prolific)
prolific$participant_id
#Merging the two files together
ds <- merge(ds, prolific, "participant_id")
nrow(ds)
####Control questions
#First if any one is NA we gie them the CORRECT answer as they did not answer the questions (i.e., if NA they have not answered it if it was a forced-answer question)
head(data)
nrow(ds)
#ds$Control2[is.na(ds$Control2)] <- 4
#Then remove those not answer correctly
ds <- ds[ds[,"Control2"]==4,]
nrow(ds)
#Next control item
#ds$Control2[is.na(ds$Control2)] <- 4
#ds <- ds[ds[,"Control2"]==4,]
#nrow(ds)
#Demographic
head(ds)
mean(ds$age)
mean(ds$age[ds$Group_Class==1], )
mean(ds$age[ds$Group_Class==0], )
sd(ds$age)
range(ds$age)
table(ds$Gender)
table(ds$Country.of.Birth)
order(table(ds$Country.of.Birth))
table(ds$Group_Class)
#Survey completion time (see also complettion time below)
ds$startdate_1 <- as.POSIXct(ds$startdate, format='%m/%d/%Y %H:%M:%S')
ds$submitdate_1 <- as.POSIXct(ds$submitdate, format='%m/%d/%Y %H:%M:%S')
#Create Time difference and remove time stamps
ds$time_Dif <- difftime(ds$submitdate_1, ds$startdate_1, units="mins")
mean(ds$time_Dif)
sd(ds$time_Dif)
#check
head(ds)
nrow(ds)
###### Semantic Questions
####Semantic questions: Combining word responses. Insert the name of the columns that should be combined. Copy line for as many semantic questions as you need
#Creative Person at work
ds$CreativePerson_all <- paste(ds$describeCPerson_creativity1, ds$describeCPerson_creativity2, ds$describeCPerson_creativity3, ds$describeCPerson_creativity4, ds$describeCPerson_creativity5, sep=" ")
ds$CreativePerson_all
#Not a creative person at work
ds$describeNotCPerson_all <- paste(ds$describeNotCPerson_notCreative1, ds$describeNotCPerson_notCreative2, ds$describeNotCPerson_notCreative3, ds$describeNotCPerson_notCreative4, ds$describeNotCPerson_notCreative5, sep=" ")
ds$describeNotCPerson_all
#Personal creativity
ds$DescribeYourC_all <- paste(ds$DescribeYourC_Ucreative1, ds$DescribeYourC_Ucreative2, ds$DescribeYourC_Ucreative3, ds$DescribeYourC_Ucreative4, ds$DescribeYourC_Ucreative5, sep=" ")
ds$DescribeYourC_all
###### RATING SCALES
#FIRST RATING SCALE
#Reverse any items if needed; for example:
#ds$ITEM_2_REVERESED <- recode(ds$ITEM_2, "1=7; 2=6; 3=5; 4=4; 5=3; 6=2; 7=1")
#Create own dataframe containing all items for a rating scales in order to check alpha and omega
head(ds)
#Merge condition 1 and 2 columns (i.e., who answered HILS versus SWLS first)
#ds$HILS1[!is.na(ds$HILS12)] = ds$HILS12[!is.na(ds$HILS12)]  # merge those answering HILS-3 first and last
#ds$HILS2[!is.na(ds$HILS22)] = ds$HILS22[!is.na(ds$HILS22)]
#ds$HILS3[!is.na(ds$HILS32)] = ds$HILS32[!is.na(ds$HILS32)]
#ds$SWLS1[!is.na(ds$SWLS11)] = ds$SWLS11[!is.na(ds$SWLS11)]
#ds$SWLS2[!is.na(ds$SWLS21)] = ds$SWLS21[!is.na(ds$SWLS21)]
#ds$SWLS3[!is.na(ds$SWLS31)] = ds$SWLS31[!is.na(ds$SWLS31)]
#ds$Control[!is.na(ds$Control2)] = ds$Control2[!is.na(ds$Control2)]
#install.packages("GPArotation")
Everydayself <- data.frame(ds$everydayself1, ds$everydaySelf2, ds$everydayself3, ds$everydayself4, ds$everydayself5,
ds$everydayself6, ds$everydayself7, ds$everydayself8, ds$everydayself9, ds$everydayself10, ds$everydayself11)
Everydayself
alpha(Everydayself)
omega(Everydayself)
Scholarly <- data.frame(ds$Scholarly12, ds$Scholarly13, ds$Scholarly14, ds$Scholarly15, ds$Scholarly16, ds$Scholarly17, ds$Scholarly18,
ds$Scholarly19, ds$Scholarly20, ds$Scholarly21, ds$Scholarly22)
Scholarly
alpha(Scholarly)
omega(Scholarly)
Preformance <- data.frame(ds$Performance23, ds$Performance24, ds$Performance25, ds$Performance26, ds$Performance27,
ds$Performance28, ds$Performance29, ds$Performance30, ds$Performance31, ds$Performance32)
Preformance
alpha(Preformance)
omega(Preformance)
MechanicalSience <- data.frame(ds$MechanicalSience33, ds$MechanicalSience34, ds$MechanicalSience35, ds$MechanicalSience36, ds$MechanicalSience37,
ds$MechanicalSience38, ds$MechanicalSience39, ds$MechanicalSience40, ds$MechanicalSience41)
MechanicalSience
alpha(MechanicalSience)
omega(MechanicalSience)
Artistic <- data.frame(ds$Artistic42, ds$Artistic43, ds$Artistic44, ds$Artistic45, ds$Artistic46,
ds$Artistic47, ds$Artistic48, ds$Artistic49, ds$Artistic50)
Artistic
alpha(Artistic)
omega(Artistic)
#Add rating scale to the dataframe called ds
head(ds)
ds$Everydayself <- c(ds$everydayself1 + ds$everydaySelf2 + ds$everydayself3 + ds$everydayself4 + ds$everydayself5 +
ds$everydayself6 + ds$everydayself7 + ds$everydayself8 + ds$everydayself9 + ds$everydayself10 + ds$everydayself11)
ds$Scholarly <- c(ds$Scholarly12 + ds$Scholarly13 + ds$Scholarly14 + ds$Scholarly15 + ds$Scholarly16 + ds$Scholarly17 + ds$Scholarly18 +
ds$Scholarly19 + ds$Scholarly20 + ds$Scholarly21 + ds$Scholarly22)
ds$Performance <- c(ds$Performance23 + ds$Performance24 + ds$Performance25 + ds$Performance26 + ds$Performance27 +
ds$Performance28 + ds$Performance29 + ds$Performance30 + ds$Performance31 + ds$Performance32)
ds$MechanicalSience <- c(ds$MechanicalSience33 + ds$MechanicalSience34 + ds$MechanicalSience35 + ds$MechanicalSience36 + ds$MechanicalSience37 +
ds$MechanicalSience38 + ds$MechanicalSience39 + ds$MechanicalSience40 + ds$MechanicalSience41)
ds$Artistic <- c(ds$Artistic42 + ds$Artistic43 + ds$Artistic44 + ds$Artistic45 + ds$Artistic46 +
ds$Artistic47 + ds$Artistic48 + ds$Artistic49 + ds$Artistic50)
ds$CreativeTotal <- c(ds$Everydayself + ds$Scholarly + ds$Performance + ds$MechanicalSience + ds$Artistic)
ds$CreativeTotal
#Look at the rating scale
library(psych)
psych::describe(ds$Everydayself)
hist(ds$Everydayself)
psych::describe(ds$Scholarly)
hist(ds$Scholarly)
psych::describe(ds$Performance)
hist(ds$Performance)
psych::describe(ds$MechanicalSience)
hist(ds$MechanicalSience)
psych::describe(ds$Artistic)
hist(ds$Artistic)
#Total
psych::describe(ds$CreativeTotal)
hist(ds$CreativeTotal)
###### Correlation among rating scales
#Correlation between two variables
cor.test(ds$Everydayself, ds$Scholarly)
cor.test(ds$Everydayself, ds$Performance)
cor.test(ds$Everydayself, ds$MechanicalSience)
cor.test(ds$Everydayself, ds$Artistic)
cor.test(ds$Scholarly, ds$Performance)
cor.test(ds$Scholarly, ds$MechanicalSience)
cor.test(ds$Scholarly, ds$Artistic)
cor.test(ds$Performance, ds$MechanicalSience)
cor.test(ds$Performance, ds$Artistic)
cor.test(ds$MechanicalSience, ds$Artistic)
#Function to correlate many items and creat "significance-stars"; note that you can change in TWO places in the function for spearman eller pearson etc
library(Hmisc)
#install.packages("Hmisc")
corstarsl <- function(x){
require(Hmisc)
x <- as.matrix(x)
R <- rcorr(x, type="pearson")$r
p <- rcorr(x, type="pearson")$P
## define notions for significance levels; spacing is important.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
## trunctuate the matrix that holds the correlations to two decimal
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
## build a new matrix that includes the correlations with their apropriate stars
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
## remove upper triangle (Original)
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- NA
Rnew <- as.data.frame(Rnew)
## remove last column and return the matrix (which is now a data frame)
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Create a dataframe with all the rating scales that you want to include in the correlation table
correlationtable <- data.frame(ds$Everydayself, ds$Scholarly, ds$Performance, ds$MechanicalSience, ds$Artistic, ds$CreativeTotal)
head(correlationtable, 10)
##Create table _insert your dataframe below
New_tableP<-corstarsl(correlationtable)
New_tableP
#Number particiants
nrow(correlationtable)
#Save correlation table in your working directory so that you can copy and past it into a table in word or Excel
write.csv(New_tableP, "Correlation_table_OK1.csv")
#Dsciding which columns to save for a file to insert to another program such as Semantic Excel; can skip this step and just write ds instead of ds_all below
#Consider starting with all the text-variables first and then the rating scale total scores for the file to be imported to Semantic Excel
#Get column names that can be copied in to the like below
dput(names(ds))
#Creat dataframe
ds_all <- ds[, c("participant_id", "id", "submitdate",
"startdate", "datestamp", "Performance26", "Artistic42", "Scholarly18",
"Artistic43", "Scholarly14", "everydayself10", "MechanicalSience34",
"Artistic47", "everydayself6", "Artistic44", "Artistic45", "MechanicalSience40",
"Performance23", "Scholarly17", "everydayself11", "Performance28",
"Performance32", "Artistic49", "Scholarly19", "Artistic50", "MechanicalSience35",
"Scholarly20", "Performance29", "MechanicalSience33", "Scholarly15",
"everydayself1", "Scholarly21", "Scholarly13", "Performance30",
"Scholarly22", "Performance31", "everydayself7", "everydayself8",
"Scholarly16", "everydayself3", "everydaySelf2", "everydayself4",
"Performance27", "everydayself5", "Artistic46", "everydayself9",
"MechanicalSience37", "Scholarly12", "MechanicalSience41", "Artistic48",
"Control2", "MechanicalSience39", "MechanicalSience36", "Performance24",
"MechanicalSience38", "Performance25",
"Group_Class", "session_id", "status", "started_datetime", "completed_date_time",
"time_taken", "age", "num_approvals", "num_rejections", "prolific_score",
"reviewed_at_datetime", "entered_code", "Gender.identity", "Country.of.Birth",
"Current.Country.of.Residence", "Sex", "Industry", "Student.Status",
"Employment.Status", "Nationality", "First.Language", "startdate_1",
"submitdate_1", "time_Dif", "Title", "jobdescription", "CreativePerson_all", "describeNotCPerson_all",
"DescribeYourC_all", "Everydayself", "Scholarly", "Performance",
"MechanicalSience", "Artistic", "CreativeTotal")]
ds_all
#Saving file to the folder you are in (i.e., that you used in "setwd()" )
write.csv(ds_all, "FileForSemanticExcel.csv")
#NORM
#Save Creative person norm.
CreativePerson_all_oneCell <- paste(ds$CreativePerson_all, collapse = ' ')
CreativePerson_all_oneCell
#Number of words
sapply(strsplit(CreativePerson_all_oneCell, " "), length)
#Most common word
library(stringr)
most_common_word <- function(s){
which.max(table(s %>% str_split(boundary("word"))))
}
most_common_word(CreativePerson_all_oneCell)
#Add uncreative 233 times
CreativePerson_all_oneCell <- c(CreativePerson_all_oneCell, rep("creative", 233))
CreativePerson_all_oneCell <- paste(CreativePerson_all_oneCell, collapse = ' ')
CreativePerson_all_oneCell
write.csv(CreativePerson_all_oneCell, "CreativePersonAtWorkNorm.csv")
#Save UN-Creative person norm.
head(ds)
NOT_CreativePerson_all_oneCell <- paste(ds$describeNotCPerson_all, collapse = ' ')
NOT_CreativePerson_all_oneCell
#Number of words
sapply(strsplit(NOT_CreativePerson_all_oneCell, " "), length)
#Most common word
most_common_word(NOT_CreativePerson_all_oneCell)
#Add uncreative 42 times
NOT_CreativePerson_all_oneCell <- c(NOT_CreativePerson_all_oneCell, rep("uncreative", 42))
NOT_CreativePerson_all_oneCell <- paste(NOT_CreativePerson_all_oneCell, collapse = ' ')
write.csv(NOT_CreativePerson_all_oneCell, "NOT_CreativePersonAtWorkNorm.csv")
#Creating correlations for Bipolar.
#Create Correaltion that also include Valence and Semantic simalirty scales from Semantic Excel
data_val_ss <- read.csv("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/SE analyses SS/FileForSemanticExcel_Short_11dec_1.csv", sep=",", header=TRUE)
head(data_val_ss)
#Renaming valence variables
data_val_ss$val_DescribeYourCall <- data_val_ss$X_predvalence.4
hist(data_val_ss$val_DescribeYourCall)
#Renaming Semantic Similairty Scales AND creating Bipolar norms
#Creativity
data_val_ss$SS_DescribeYourCall_Creative  <- data_val_ss$X_creativityatworknormOK
hist(data_val_ss$SS_DescribeYourCall_Creative)
data_val_ss$SS_DescribeYourCall_Uncreative <- data_val_ss$X_uncreativityatworknormOK
hist(data_val_ss$SS_DescribeYourCall_Uncreative)
#Bipolar norm
data_val_ss$SS_DescribeYourCall_Bipolar <- data_val_ss$SS_DescribeYourCall_Creative - data_val_ss$SS_DescribeYourCall_Uncreative
hist(data_val_ss$SS_DescribeYourCall_Bipolar)
head(data_val_ss)
correlationtable2 <- data.frame(data_val_ss$SS_DescribeYourCall_Bipolar, data_val_ss$val_DescribeYourCall,
data_val_ss$X_Everydayself, data_val_ss$X_Scholarly, data_val_ss$X_Performance,
data_val_ss$X_MechanicalSience, data_val_ss$X_Artistic, data_val_ss$X_CreativeTotal)
##Create table _insert your dataframe below
New_tableP2<-corstarsl(correlationtable2)
New_tableP2
#Number particiants
nrow(correlationtable2)
describe_variables <- psych::describe(correlationtable2)
#Save correlation table in your working directory so that you can copy and past it into a table in word or Excel
write.csv(New_tableP2, "/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/Correlation_table_large.csv")
write.csv(describe_variables, "/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/describe_variables.csv")
#Creating dataset for Semantics so we can plot words according to bipolar scale.
dput(names(data_val_ss))
#Creat dataframe
ds_all2 <- data_val_ss[, c("X_identifier", "X_", "X_participantid", "X_id", "X_Genderidentity",
"X_Sex", "X_timeDif", "X_Title", "X_jobdescription", "X_CreativePersonall",
"X_describeNotCPersonall", "X_DescribeYourCall", "X_Everydayself",
"X_Scholarly", "X_Performance", "X_MechanicalSience", "X_Artistic",
"X_CreativeTotal", "X_GroupClass", "X_age", "X_GenderF1M2", "X_predvalence",
"X_predvalence.1", "X_predvalence.2", "X_predvalence.3", "X_predvalence.4",
"X_DescribeYourCall.1", "X_creativityatworknormOK", "X_uncreativityatworknormOK",
"X_creativityatworknormOK.1", "X_uncreativityatworknormOK.1",
"val_DescribeYourCall", "SS_DescribeYourCall_Creative", "SS_DescribeYourCall_Uncreative",
"SS_DescribeYourCall_Bipolar")]
ds_all2
write.csv(ds_all2, "/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/FileForSemanticExcel_Well-BeingWorks_Bipolar.csv")
#Comparing the Measures in relation to the Creative Class.
head(ds_all2)
mean(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0])
mean(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
sd(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0])
sd(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
length(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0])
length(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
t.test(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0], ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
mean(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0])
mean(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
sd(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0])
sd(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
length(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0])
length(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
t.test(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0], ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
ds_all2$X_CreativeTotal
mean(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0])
mean(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
sd(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0])
sd(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
length(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0])
length(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
t.test(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0], ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
t.test(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0], ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
t.test(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0], ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
t.test(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0], ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
getwd()
Description <-  read.csv("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/Sätta nummer på titel och jobbeskrivning .csv", sep=",", header=TRUE)
Description <-  read.csv("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/Amalia & Claudia/Sätta nummer på titel och jobbeskrivning + Eva.csv", sep=";", header=TRUE)
head(Description)
raters_df <- Description[, c("Eva.ratedJC", "X_RatedTJCreativty", "X_RatedTJCreativty.1")]
#install.packages("irr")
library(irr)
icc(raters_df, model= "twoway", type="agreement")
icc(raters_df, model= "oneway", type="agreement")
alpha(raters_df)
library(irr)
icc(raters_df, model= "twoway", type="agreement")
sd(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 0])
sd(ds_all2$SS_DescribeYourCall_Bipolar[ds_all2$X_GroupClass == 1])
sd(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 0])
sd(ds_all2$val_DescribeYourCall[ds_all2$X_GroupClass == 1])
sd(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 0])
sd(ds_all2$X_CreativeTotal[ds_all2$X_GroupClass == 1])
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
x  <-  "I am here"
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
x  <-  "I am here"
y1  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 10,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y1
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
# Run python file with hungface interface
source_python("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/R/huggingface_interface.py")
y12  <-  hgTransformerGetEmbedding(text_strings = x,
pretrained_weights = 'bert-base-uncased',
tokenizer_class = BertTokenizer,
model_class = BertModel,
num_hidden_layers = 9,  #all or a list of layers to keep
return_tokens = FALSE) #setting does not work
y12
identical(y1, y12)
y1
