normG2 <- group2[ folds[[i]], ]
normG2_words <- data.frame(unlist(strsplit(tolower(normG2$words), " ")))
normG2_words1 <- tibble::as_tibble(as.character(normG2_words$unlist.strsplit.tolower.normG2.words........))
# Get the words's word embeddings
#Function to apply the semantic representation to ONE word; and return vector with NA if word is not found
applysemrep_plot <- function(x, Ndim){
#If semrep is found get it; if not return NA vector of dimensions (which equal "Ndim"=space[["s"]][[14]] )
if (sum(single_wordembeddings_df$words == x[TRUE]) %in% 1) {
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- single_wordembeddings_df[single_wordembeddings_df$words ==x, ]
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
#If the word does not have a semrep return vector with Ndim (512) dimensions of NA; Ndim=768
}else if (x %in% NA) {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
class(wordrep)
wordrep <- as.numeric(wordrep)
} else {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
wordrep <- as.numeric(wordrep)
}
}
#Get word embeddings for each word
group1_single1 <- sapply(normG1_words1$value, applysemrep_plot)
group1_single2 <- tibble::as_tibble(t(group1_single1))
group2_single1 <-  sapply(normG2_words1$value, applysemrep_plot)
group2_single2 <- tibble::as_tibble(t(group2_single1))
# Adds the Semantic Difference Representation into a Tibble and then duplicates it
# to as many rows as it will be compared to with x (nrow(normX))
# For x: Only get the word embeddings and make them numeric
group1_single3 <- group1_single2 %>%
dplyr::mutate_if(is.character,as.numeric)
# Get as many SemDifRep as group_single3 so that it can be compred
semDifRep_x <- tibble::as_tibble(t(semDifRep)) %>%
dplyr::slice(rep(dplyr::row_number(), nrow(group1_single2)))
# Get Semantic Similairty score between words and SemDifRep
group1_single4_ss <- cosines(group1_single3, semDifRep_x)
group1_single4_ss_1 <- tibble::tibble(normG1_words1$value, group1_single4_ss)
# For y: Only get the word embeddings and make them numeric
group2_single3 <- group2_single2 %>%
dplyr::mutate_if(is.character,as.numeric)
# Get as many SemDifRep as y3 so that it can be compred
semDifRep_y <- as_tibble(t(semDifRep)) %>%
dplyr::slice(rep(dplyr::row_number(), nrow(group2_single2)))
# Get Semantic Similairty score between words and SemDifRep
group2_single4_ss <- cosines(group2_single3, semDifRep_y)
group2_single4_ss_1 <- tibble(normG2_words1$value, group2_single4_ss)
# Lists to save the restuls in
semanticTtestscoreslistG1[[i]] <- group1_single4_ss_1
semanticTtestscoreslistG2[[i]] <- group2_single4_ss_1
}
# Sorting out a dataframe for the resuts; bind the list of tibbles together to one
semanticTtestscoreslistG1done <- dplyr::bind_rows(semanticTtestscoreslistG1)
colnames(semanticTtestscoreslistG1done) <- c("words", "SS")
semanticTtestscoreslistG1done$g1_1_g2_2 <- rep(1, nrow(semanticTtestscoreslistG1done))
semanticTtestscoreslistG2done <- dplyr::bind_rows(semanticTtestscoreslistG2)
colnames(semanticTtestscoreslistG2done) <- c("words", "SS")
semanticTtestscoreslistG2done$g1_1_g2_2 <- rep(2, nrow(semanticTtestscoreslistG2done))
# Bind all words together
semanticTtestscoreslistG1G2done <- dplyr::bind_rows(semanticTtestscoreslistG1done, semanticTtestscoreslistG2done)
# Getting Descriptives of the words
# All words SS mean to the semantic comparison representation
words_mean <- mean(semanticTtestscoreslistG1G2done$SS, na.rm=TRUE)
# All words SD to the semantic comparison representation
words_sd <- stats::sd(semanticTtestscoreslistG1G2done$SS, na.rm=TRUE)
# Each word's mean and sd (i.e., they may have different SS score due to being in different K-folds)
Words_info <- dplyr::group_by(semanticTtestscoreslistG1G2done, words) %>%
dplyr::summarize(mean = mean(SS))
Words_info_sd <- dplyr::group_by(semanticTtestscoreslistG1G2done, words) %>%
dplyr::summarize(sd = stats::sd(SS))
semanticTtestscoreslistG1G2done$words
table(semanticTtestscoreslistG1G2done$words, useNA = "always" )
# The n/frequency of each word
Words_info$n <- as.numeric(table(semanticTtestscoreslistG1G2done$words, useNA = "ifany"))
Words_info$sd <-  Words_info_sd$sd
#Add the max SD to the words that do not have a SD
Words_info$sd[is.na(Words_info$sd)] <- max(Words_info$sd, na.rm = T)
# To get the p-values even for words only occuring once; I make n = 1 to n = 2.
# Words_info$n_2 <- Words_info$n
# Words_info$n_2[Words_info$n_2 == 1] <- 2
# Computing t-tests: library(BSDA) tsum.test(mean.x=.1,   s.x=.01, n.x=2, mean.y=.136, s.y=.02, n.y=7)
# Words_info$n_2 adds so it is at least 2 words; and more t-tests can be made.
n_total_words <- sum(Words_info$n)
Words_ttest <- data.frame(mapply(BSDA::tsum.test,
mean.x = Words_info$mean, s.x = Words_info$sd, n.x = Words_info$n,
mean.y = words_mean, s.y = words_sd, n.y = n_total_words-Words_info$n,
var.equal = FALSE))
# Pulling out the t-statistics and p-values from the t-test done above
p_values <- t(Words_ttest[1:nrow(Words_info)][3,])
Words_info$p_values <- unlist(p_values)
t_statistic <- t(Words_ttest[1:nrow(Words_info)][1,])
Words_info$t_statistic <- unlist(t_statistic)
# Function for Computing Cohen's D (https://www.socscistatistics.com/effectsize/default3.aspx)
cohens_d <- function(mean_x, sd_x, n_x, mean_y, sd_y, n_y) {
(mean_x - mean_y)/ (sqrt((sd_x^2 + sd_y^2)/2))
}
# Applying Cohens D individually for each word
cohen_D_df <- data.frame(mapply(cohens_d,
mean_x = Words_info$mean, sd_x = Words_info$sd, n_x = Words_info$n,    #Words_info$n_2 adds so it is at least 2 words; and more t-tests can be made.
mean_y = words_mean, sd_y = words_sd, n_y = n_total_words-Words_info$n))
colnames(cohen_D_df) <- "cohensD"
Words_info$cohensD <- cohen_D_df$cohensD
word_data_list[i_dim] <- list(Words_info)
}
# Arranging it to one tibble; accounting for x versus x and y input
if (is.null(y)==TRUE) {
word_data_tibble <- word_data_list[[1]]
colnames(word_data_tibble) <- c("words", "mean.x", "n.x", "sd.x",
"p_values.x", "t_statistic.x", "cohensD.x")
} else {
word_data_tibble <- dplyr::full_join(word_data_list[[1]], word_data_list[[2]], by = "words")
}
# Bonferroni correction or not
if (isTRUE(Bonferroni) == TRUE) {
# If there are no y axes or not.
if ( is.null(y) == TRUE) {
bonferroni_x <- as.numeric(table(!is.na(word_data_tibble$p_values.x))["TRUE"])
word_data_tibble_bonf <- word_data_tibble[word_data_tibble$p_values.x < .05/bonferroni_x, ]
} else {
# Counting number of t-test made (i.e, on words more than 1)
bonferroni_x <- as.numeric(table(!is.na(word_data_tibble$p_values.x))["TRUE"])
bonferroni_y <- as.numeric(table(!is.na(word_data_tibble$p_values.y))["TRUE"])
# Select significant words when Bonferroni correcting for multiple comparison
word_data_tibble_bonf <- word_data_tibble[word_data_tibble$p_values.x < .05/bonferroni_x | word_data_tibble$p_values.y < .05/bonferroni_y , ]
}
# Remove NAs
word_data_tibble <- word_data_tibble_bonf[!is.na(word_data_tibble_bonf$words),]
word_data_tibble
} else {
word_data_tibble
}
word_data_tibble
}
library(text)
library(text)
library(text)
x <- sq_data_tutorial8_10[1:2, 1:2]
x
layer_indexes_RBERT = 12
batch_size_IBT = 2L
token_index_IBT = 1
layer_index_IBT = 12
# Download pre-trained BERT model. This will go to an appropriate cache
# directory by default.
BERT_PRETRAINED_DIR <- RBERT::download_BERT_checkpoint(
model = "bert_base_uncased")
# Select all character variables
x_characters <- dplyr::select_if(x, is.character)
# Get word-embeddings for all individual-words
#Unite all text variables into one
x_characters2 <- tidyr::unite(x_characters, "x_characters2", 1:ncol(x_characters), sep = " ")
# unite all rows in the column into one cell
x_characters3 <- paste(x_characters2[1], collapse = ' ')
#Remove remove all punctuation characters
x_characters4 <- stringr::str_replace_all(x_characters3, "[[:punct:]]", " ")
#Remove  \n
x_characters5 <- gsub("[\r\n]", " ", x_characters4)
x_characters6 <- gsub("[\n]", " ", x_characters5)
#Tokenize into single words
x_characters7 <- tokenizers::tokenize_words(x_characters6, simplify=T)
#Create datafrema with single words and frequency
x_characters8 <- data.frame(sort(table(unlist(strsplit(tolower(x_characters7), " ")))))
singlewords <- tibble(x_characters8$Var1, x_characters8$Freq)
colnames(singlewords) <- c("words", "n")
singlewords$words <- as.character(singlewords$words)
# Tokenize words to list
tokenized_sentences1_sw <- singlewords$words
# Extract BERT feature
BERT_feats_sw <- RBERT::extract_features(
examples = RBERT::make_examples_simple(tokenized_sentences1_sw),
ckpt_dir = BERT_PRETRAINED_DIR,
layer_indexes = layer_indexes_RBERT,
batch_size = batch_size_IBT) # , ...
BERT_feats_sw
# Extract/Sort output vectors for all words.
output_vectors_sw <- BERT_feats_sw$output %>%
dplyr::filter(token_index == token_index_IBT, layer_index == layer_index_IBT)
#Add frequency for each word
singlewords_we1 <- cbind(singlewords, output_vectors_sw)
singlewords_we <- tibble::as_tibble(singlewords_we1)
# Add the single words embeddings
output_vectors_sw <- list()
output_vectors_sw$singlewords_we <- singlewords_we
output_vectors_sw
# Get a word variable
x_characters
Ndim=768
# Look up word embeddings for each word in output_vectors_sw
# Get the words' word embeddings
#Function to apply the semantic representation to ONE word; and return vector with NA if word is not found
applysemrep_plot <- function(x){
#If semrep is found get it; if not return NA vector of dimensions (which equal "Ndim"=space[["s"]][[14]] )
if (sum(single_wordembeddings_df$words == x[TRUE]) %in% 1) {
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- single_wordembeddings_df[single_wordembeddings_df$words ==x, ]
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
#If the word does not have a semrep return vector with Ndim (512) dimensions of NA; Ndim=768
}else if (x %in% NA) {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
class(wordrep)
wordrep <- as.numeric(wordrep)
} else {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
wordrep <- as.numeric(wordrep)
}
}
x_characters
# Get a word variable
x_characters[1]
# Summerise the word embeddings
group1_single1 <- sapply(x_characters[1], applysemrep_plot)
output_vectors_sw
# Look up word embeddings for each word in output_vectors_sw
# Get the words' word embeddings
#Function to apply the semantic representation to ONE word; and return vector with NA if word is not found
applysemrep_plot <- function(x){
#If semrep is found get it; if not return NA vector of dimensions (which equal "Ndim"=space[["s"]][[14]] )
if (sum(singlewords_we$words == x[TRUE]) %in% 1) {
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- single_wordembeddings_df[single_wordembeddings_df$words ==x, ]
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
#If the word does not have a semrep return vector with Ndim (512) dimensions of NA; Ndim=768
}else if (x %in% NA) {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
class(wordrep)
wordrep <- as.numeric(wordrep)
} else {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
wordrep <- as.numeric(wordrep)
}
}
# Summerise the word embeddings
group1_single1 <- sapply(x_characters[1], applysemrep_plot)
group1_single1
x_characters[1]
# Look up word embeddings for each word in output_vectors_sw
# Get the words' word embeddings
#Function to apply the semantic representation to ONE word; and return vector with NA if word is not found
applysemrep_plot <- function(x){
#If semrep is found get it; if not return NA vector of dimensions (which equal "Ndim"=space[["s"]][[14]] )
if (sum(singlewords_we$words == x[TRUE]) %in% 1) {
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- singlewords_we[singlewords_we$words ==x, ]
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
#If the word does not have a semrep return vector with Ndim (512) dimensions of NA; Ndim=768
}else if (x %in% NA) {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
class(wordrep)
wordrep <- as.numeric(wordrep)
} else {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
wordrep <- as.numeric(wordrep)
}
}
# Summerise the word embeddings
group1_single1 <- sapply(x_characters[1], applysemrep_plot)
group1_single1
x_characters[1]
x=peaceful
x <- peaceful
x <- peaceful
x <- "peaceful"
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- singlewords_we[singlewords_we$words ==x, ]
word1rep
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
wordrep
#if x= "" replace with NA
# Generic function to apply a common semantic representaion for ALL words in a CELL; and if there are no words return a Ndim vector with NAs
semanticrepresentation <- function(x) {
x <- tolower(x)
#Separates the words in a cell into a character vector with separate words.
x <- data.frame(unlist(str_extract_all(x, "[[:alpha:]]+")))
colnames(x) <- c("wordsAll1")
x <- as.tibble(x)
x <- as.character(x$wordsAll1)
#If empty return a NA semantic representation
if (length(x)== 0){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
# Create a matrix with all the semantic representations using the function above
#x1 <-  apply(x, 1, applysemrep)
x1 <-  sapply(x, applysemrep_plot)
#IF more than one semrep; Sum all the semantic represenations; if not return it as is so that NA etc is returned/kept
x2 <- Matrix::rowSums(x1, na.rm=TRUE)
#If all values are 0 they should be NA instead; otherwise return the semantic representation.
if (all(x2 == 0)== TRUE){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
x2 <- x2
}
}
# Loop for all word variables
}
semanticrepresentation(x_characters[1])
library(stringr)
#if x= "" replace with NA
# Generic function to apply a common semantic representaion for ALL words in a CELL; and if there are no words return a Ndim vector with NAs
semanticrepresentation <- function(x) {
x <- tolower(x)
#Separates the words in a cell into a character vector with separate words.
x <- data.frame(unlist(str_extract_all(x, "[[:alpha:]]+")))
colnames(x) <- c("wordsAll1")
x <- as.tibble(x)
x <- as.character(x$wordsAll1)
#If empty return a NA semantic representation
if (length(x)== 0){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
# Create a matrix with all the semantic representations using the function above
#x1 <-  apply(x, 1, applysemrep)
x1 <-  sapply(x, applysemrep_plot)
#IF more than one semrep; Sum all the semantic represenations; if not return it as is so that NA etc is returned/kept
x2 <- Matrix::rowSums(x1, na.rm=TRUE)
#If all values are 0 they should be NA instead; otherwise return the semantic representation.
if (all(x2 == 0)== TRUE){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
x2 <- x2
}
}
# Loop for all word variables
}
semanticrepresentation(x_characters[1])
oktest <- semanticrepresentation(x_characters[1])
oktest
oktest <- as_tibble(t(sapply(x_characters[1], semanticrepresentation)))
oktest
oktest <- as_tibble(t(sapply(x_characters[[1]], semanticrepresentation)))
oktest
x_characters
#Create empty list
list_semrep <- list()
#For loop that apply the semrep to each character variable
for (i in 1:length(x_characters)) {
#Apply the semantic representation funtion to all rows; transpose the resulting matrix and making a tibble
list_semrep[[i]] <- as_tibble(t(sapply(x_characters[[i]], semanticrepresentation)))
}
#Gives the tibbles in the list the same name as the orginal character variables
names(list_semrep) <- names(x_characters)
list_semrep
x <- sq_data_tutorial8_10[1:2, 1:2]
x
textImportWords <- function(x, layer_indexes_RBERT = 12, batch_size_IBT = 2L, token_index_IBT = 1,
layer_index_IBT = 12,  ...){
# Download pre-trained BERT model. This will go to an appropriate cache
# directory by default.
BERT_PRETRAINED_DIR <- RBERT::download_BERT_checkpoint(
model = "bert_base_uncased")
# Select all character variables
x_characters <- dplyr::select_if(x, is.character)
#Single words' word embeddings
# Get word-embeddings for all individual-words
#Unite all text variables into one
x_characters2 <- tidyr::unite(x_characters, "x_characters2", 1:ncol(x_characters), sep = " ")
# unite all rows in the column into one cell
x_characters3 <- paste(x_characters2[1], collapse = ' ')
#Remove remove all punctuation characters
x_characters4 <- stringr::str_replace_all(x_characters3, "[[:punct:]]", " ")
#Remove  \n
x_characters5 <- gsub("[\r\n]", " ", x_characters4)
x_characters6 <- gsub("[\n]", " ", x_characters5)
#Tokenize into single words
x_characters7 <- tokenizers::tokenize_words(x_characters6, simplify=T)
#Create datafrema with single words and frequency
x_characters8 <- data.frame(sort(table(unlist(strsplit(tolower(x_characters7), " ")))))
singlewords <- tibble(x_characters8$Var1, x_characters8$Freq)
colnames(singlewords) <- c("words", "n")
singlewords$words <- as.character(singlewords$words)
# Tokenize words to list
tokenized_sentences1_sw <- singlewords$words
# Extract BERT feature
BERT_feats_sw <- RBERT::extract_features(
examples = RBERT::make_examples_simple(tokenized_sentences1_sw),
ckpt_dir = BERT_PRETRAINED_DIR,
layer_indexes = layer_indexes_RBERT,
batch_size = batch_size_IBT) # , ...
BERT_feats_sw
# Extract/Sort output vectors for all words.
output_vectors_sw <- BERT_feats_sw$output %>%
dplyr::filter(token_index == token_index_IBT, layer_index == layer_index_IBT)
#Add frequency for each word
singlewords_we1 <- cbind(singlewords, output_vectors_sw)
singlewords_we <- tibble::as_tibble(singlewords_we1)
# Add the single words embeddings
output_vectors_sw <- list()
output_vectors_sw$singlewords_we <- singlewords_we
output_vectors_sw
# Get a word variable
x_characters[1]
x <- "peaceful"
# Look up word embeddings for each word in output_vectors_sw
# Get the words' word embeddings
# Function to apply the semantic representation to ONE word; and return vector with NA if word is not found
applysemrep_plot <- function(x){
#If semrep is found get it; if not return NA vector of dimensions (which equal "Ndim"=space[["s"]][[14]] )
if (sum(singlewords_we$words == x[TRUE]) %in% 1) {
x <- tolower(x)
#Get the semantic representation for a word=x
word1rep <- singlewords_we[singlewords_we$words ==x, ]
#Only get the semantic represenation as a vector without the actual word in the first column
wordrep <- purrr::as_vector(word1rep[,8:length(word1rep)])
#If the word does not have a semrep return vector with Ndim (512) dimensions of NA; Ndim=768
}else if (x %in% NA) {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
class(wordrep)
wordrep <- as.numeric(wordrep)
} else {
wordrep <- data.frame(matrix(ncol = Ndim, nrow = 1))
wordrep <- as.numeric(wordrep)
}
}
# Function to apply a common semantic representaion for ALL words in a CELL; and if there are no words return a Ndim vector with NAs
# The function is using above applysemrep_plot function
semanticrepresentation <- function(x) {
x <- tolower(x)
#Separates the words in a cell into a character vector with separate words.
x <- data.frame(unlist(stringr::str_extract_all(x, "[[:alpha:]]+")))
colnames(x) <- c("wordsAll1")
x <- as.tibble(x)
x <- as.character(x$wordsAll1)
#If empty return a NA semantic representation
if (length(x)== 0){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
# Create a matrix with all the semantic representations using the function above
#x1 <-  apply(x, 1, applysemrep)
x1 <-  sapply(x, applysemrep_plot)
#IF more than one semrep; Sum all the semantic represenations; if not return it as is so that NA etc is returned/kept
x2 <- Matrix::rowSums(x1, na.rm=TRUE)
# If all values are 0 they should be NA instead; otherwise return the semantic representation.
if (all(x2 == 0)== TRUE){
x2 <- data.frame(matrix(ncol = Ndim, nrow = 1))
x2 <- as.numeric(x2)
}else{
x2 <- x2
}
}
}
# The semanticrepresentation function is now looped over all variables in x_characters
# Creating empty list
list_semrep <- list()
# For loop that apply the word embeddings to each character variable
for (i in 1:length(x_characters)) {
# Apply the semanticrepresentation function to all rows; transpose the resulting matrix and making a tibble
list_semrep[[i]] <- as_tibble(t(sapply(x_characters[[i]], semanticrepresentation)))
}
# Gives the tibbles in the list the same name as the orginal character variables
names(list_semrep) <- names(x_characters)
list_semrep
}
decontext_we <- textImportWords(x)
decontext_we
library(text)
sq_data_tutorial8_10[1:2, 1:2]
devtools::document()
library(text)
devtools::document()
library(text)
library(text)
devtools::document()
devtools::document()
library(text)
usethis::use_package("Matrix")
library(RCurl)
valence_prediction_model <- readRDS(url("https://oscarkjell.se/text_models/trained_anew1999_valence.rda"))
install.packages(c("BH", "bit", "bookdown", "caret", "caTools", "cli", "fansi", "foreign", "gplots", "gsl", "hms", "ModelMetrics", "mvtnorm", "prabclus", "prettyunits", "qdap", "ranger", "recipes", "robCompositions", "RSQLite", "Rttf2pt1", "SQUAREM", "stringi", "tinytex", "vcd", "xfun", "zoo"))
version(RBERT)
version("RBERT")
versions("RBERT")
package.version("RBERT")
# Load data to test with
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text_data_examples/wordembeddings4_100.rda")
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/data/sq_data_tutorial4_100.rda")
package_version(RBERT)
# Load data to test with
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text_data_examples/wordembeddings4_100.rda")
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/data/sq_data_tutorial4_100.rda")
package_version("RBERT")
library(RBERT)
package.version("RBERT")
# Load data to test with
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text_data_examples/wordembeddings4_100.rda")
# load("/Users/oscar/Desktop/0 Studies/5 R statistical semantics package/text/data/sq_data_tutorial4_100.rda")
package_version("RBERT")
packageVersion("RBERT")
# install.packages("devtools")
devtools::install_github(
"jonathanbratt/RBERT",
build_vignettes = TRUE
)
packageVersion("RBERT")
library(text)
#but == 0.1.9 is required
.rs.restartR()
#but == 0.1.9 is required
.rs.restartR()
.rs.restartR()
