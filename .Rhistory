tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-cased"){
pretrained_weights = 'distilbert-base-cased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
}
pretrained_weights
tokenizer_class
model_class
devtools::document()
library(text)
devtools::document()
library(text)
x <- Language_based_assessment_data_8_10[1:2, 1:2]
x <- Language_based_assessment_data_8_10[1, 1]
x
wordembeddings_1 <- textHuggingFace(x, layers = 'all', model = "bert-base-uncased")
wordembeddings_2 <- textHuggingFace(x, layers = 'all', model = "openai-gpt")
wordembeddings_2 <- textHuggingFace(x, layers = 'all', model = "openai-gpt")
wordembeddings_3 <- textHuggingFace(x, layers = 'all', model = "gpt2")
wordembeddings_4 <- textHuggingFace(x, layers = 'all', model = "ctrl")
wordembeddings_4
wordembeddings_5 <- textHuggingFace(x, layers = 'all', model = "transfo-xl-wt103")
wordembeddings_5
#
wordembeddings_6 <- textHuggingFace(x, layers = 'all', model = "xlnet-base-cased")
#
wordembeddings_7 <- textHuggingFace(x, layers = 'all', model = "xlm-mlm-enfr-1024")
wordembeddings_8 <- textHuggingFace(x, layers = 'all', model = "distilbert-base-cased")
wordembeddings_9 <- textHuggingFace(x, layers = 'all', model = "roberta-base")
wordembeddings_9
wordembeddings_10 <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-base")
wordembeddings_10
devtools::document()
library(text)
wordembeddings_8 <- textHuggingFace(x, layers = 'all', model = "distilbert-base-uncased")
wordembeddings_8 <- textHuggingFace(x, layers = 'all', model = "distilbert-base-uncased")
wordembeddings_1 <- textHuggingFace(x, layers = 'all', model = "bert-base-uncased")
wordembeddings_2 <- textHuggingFace(x, layers = 'all', model = "openai-gpt")
wordembeddings_3 <- textHuggingFace(x, layers = 'all', model = "gpt2")
wordembeddings_3 <- textHuggingFace(x, layers = 'all', model = "gpt2")
# Setting up the specifics of the models; the parameters for HuggingFace.
if(model == "bert-base-uncased"){
pretrained_weights = 'bert-base-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-uncased"){
pretrained_weights = 'bert-base-multilingual-uncased'
tokenizer_class = BertTokenizer
model_class = BertModel
} else if (model == "bert-base-multilingual-cased"){
pretrained_weights = 'bert-base-multilingual-cased'
tokenizer_class = BertTokenizer
model_class = BertModel
}  else if (model == "openai-gpt"){
pretrained_weights = 'openai-gpt'
tokenizer_class = OpenAIGPTTokenizer
model_class = OpenAIGPTModel
} else if (model == "gpt2"){
pretrained_weights = 'GPT2Tokenizer'
tokenizer_class = OpenAIGPTTokenizer
model_class = GPT2Model
} else if (model == "ctrl"){
pretrained_weights = 'ctrl'
tokenizer_class = CTRLTokenizer
model_class = CTRLModel
} else if (model == "transfo-xl-wt103"){
pretrained_weights = 'transfo-xl-wt103'
tokenizer_class = TransfoXLTokenizer
model_class = TransfoXLModel
} else if (model == "xlnet-base-cased"){
pretrained_weights = 'xlnet-base-cased'
tokenizer_class = XLNetTokenizer
model_class = XLNetModel
} else if (model == "xlm-mlm-enfr-1024"){
pretrained_weights = 'xlm-mlm-enfr-1024'
tokenizer_class = XLMTokenizer
model_class = XLMModel
} else if (model == "distilbert-base-uncased"){
pretrained_weights = 'distilbert-base-uncased'
tokenizer_class = DistilBertTokenizer
model_class = DistilBertModel
} else if (model == "roberta-base"){
pretrained_weights = 'roberta-base'
tokenizer_class = RobertaTokenizer
model_class = RobertaModel
} else if (model == "xlm-roberta-base"){
pretrained_weights = 'xlm-roberta-base'
tokenizer_class = XLMRobertaTokenizer
model_class = XLMRobertaModel
}
devtools::document()
library(text)
wordembeddings_1b <- textHuggingFace(x, layers = 'all', model = "bert-base-multilingual-uncased")
wordembeddings_1b
wordembeddings_1c <- textHuggingFace(x, layers = 'all', model = "bert-base-multilingual-cased")
wordembeddings_1c
devtools::document()
library(text)
wordembeddings_10b <- textHuggingFace(x, layers = 'all', model = "xlm-roberta-large")
wordembeddings_10b
model=NULL
is.NULL(model)
is.null(model)
library(text)
devtools::install_github("oscarkjell/text")
devtools::install_github("oscarkjell/text", auth_token = 44f269339bb0ea5776f77ccb3c3e582f59a2164c)
.onAttach <- function(libname, pkgname){
if(!grepl(x = R.Version()$arch, pattern = "64")){
warning("The text package requires running R on a 64-bit systems as it is dependent on torch from ptyhon; and you are not doing this.")
}
packageStartupMessage(cat(paste0("\033[0;", 32, "m", "This is text (version 0.6.0.9000).","\033[0m","\n"),
paste0("\033[0;", 34, "m", "Newer versions may have updated default settings to reflect current understandings of the state-of-the-art.","\033[0m")))
}
devtools::install_github("oscarkjell/text", auth_token = "44f269339bb0ea5776f77ccb3c3e582f59a2164c")
# devtools::document()
# devtools::check()
# devtools::install_github("oscarkjell/text", auth_token = "44f269339bb0ea5776f77ccb3c3e582f59a2164c")
#?install_github
?install_github
# devtools::document()
# devtools::check()
devtools::install_github("oscarkjell/text", auth_token = "44f269339bb0ea5776f77ccb3c3e582f59a2164c")
# devtools::document()
# devtools::check()
devtools::install_github("OscarKjell/text", auth_token = "44f269339bb0ea5776f77ccb3c3e582f59a2164c")
devtools::install_github("OscarKjell/text", auth_token = "99a9388f1ef7a1e44b94f3650d9aeb7ea0658bea")
library(text)
devtools::document()
library(text)
library(text)
x <- Language_based_assessment_data_8_10[1:2, 1:2]
wordembeddings <- textHuggingFace(x, layers = 'all')
library(text)
library(text)
devtools::document()
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("inst/python", "huggingface_Interface3.py", package="text"))
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("inst/python/", "huggingface_Interface3.py", package="text"))
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("inst/python/", "huggingface_Interface3.py"))
help(system.file)
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("/inst/python/", "huggingface_Interface3.py", package="text", mustWork = TRUE))
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("./inst/python/", "huggingface_Interface3.py", package="text", mustWork = TRUE))
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("~/inst/python/", "huggingface_Interface3.py", package="text", mustWork = TRUE))
# Run python file with HunggingFace interface to state-of-the-art transformers
# reticulate::source_python("~/inst/python/huggingface_Interface3.py")
reticulate::source_python(system.file("/python/", "huggingface_Interface3.py", package="text", mustWork = TRUE))
devtools::document()
library(text)
library(text)
devtools::document()
devtools::document()
library(text)
devtools::document()
library(text)
library(text)
devtools::document()
library(text)
x <- Language_based_assessment_data_8_10[1:2, 1:2]
wordembeddings <- textHuggingFace(x, layers = 'all')
wordembeddings
library(text)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
centrality_data_harmony
#' @param legend_y_position Position on the y coordinates of the color legend (default: 0.05).
#' @param legend_h_size Height of the color legend (default 0.15).
#' @param legend_w_size Width of the color legend (default 0.15).
#' @param legend_title_size Font size of the title (default = 7).
#' @param legend_number_size Font size of the values in the legend (default = 2).
#' @return A 1-dimensional word plot based on cosine similarity to the aggregated word embedding.
#' @examples
#' # The test-data included in the package is called: centrality_data_harmony
#'names(centrality_data_harmony)
#' # Plot
centrality_plot <- textCentralityPlot(
#' @param legend_y_position Position on the y coordinates of the color legend (default: 0.05).
#' @param legend_h_size Height of the color legend (default 0.15).
#' @param legend_w_size Width of the color legend (default 0.15).
#' @param legend_title_size Font size of the title (default = 7).
#' @param legend_number_size Font size of the values in the legend (default = 2).
#' @return A 1-dimensional word plot based on cosine similarity to the aggregated word embedding.
#' @examples
#' # The test-data included in the package is called: centrality_data_harmony
#'names(centrality_data_harmony)
#' # Plot
centrality_plot <- textCentralityPlot(
centrality_data_harmony
centrality_data_harmony
centrality_data_harmony
#' @param legend_y_position Position on the y coordinates of the color legend (default: 0.05).
#' @param legend_h_size Height of the color legend (default 0.15).
#' @param legend_w_size Width of the color legend (default 0.15).
#' @param legend_title_size Font size of the title (default = 7).
#' @param legend_number_size Font size of the values in the legend (default = 2).
#' @return A 1-dimensional word plot based on cosine similarity to the aggregated word embedding.
#' @examples
#' # The test-data included in the package is called: centrality_data_harmony
#'names(centrality_data_harmony)
#' # Plot
centrality_plot <- textCentralityPlot(
centrality_data_harmony
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
library(text)
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
textCentralityPlot
library(text)
library(text)
help(textCentralityPlot)
centrality_data_harmony
names(centrality_data_harmony)
#' @param legend_x_axes_label Label on the color legend (default: "(x)".
#' @param legend_x_position Position on the x coordinates of the color legend (default: 0.02).
#' @param legend_y_position Position on the y coordinates of the color legend (default: 0.05).
#' @param legend_h_size Height of the color legend (default 0.15).
#' @param legend_w_size Width of the color legend (default 0.15).
#' @param legend_title_size Font size of the title (default = 7).
#' @param legend_number_size Font size of the values in the legend (default = 2).
#' @return A 1-dimensional word plot based on cosine similarity to the aggregated word embedding.
#' @examples
# The test-data included in the package is called: centrality_data_harmony
names(centrality_data_harmony)
# Plot
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
#'
#' @seealso see \code{\link{textCentralityData}} and \code{\link{textProjectionData}}
#' @importFrom dplyr arrange slice filter between left_join transmute mutate case_when
#' @importFrom ggplot2 position_jitter element_text element_blank coord_fixed theme theme_void theme_minimal aes labs scale_color_identity
#' @importFrom rlang sym
#' @export
textCentralityPlot <- function(word_data,
min_freq_words = 1,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
y_axes_values = element_blank(),
scale_x_axes_lim = NULL, #c(0.5, 1),
scale_y_axes_lim = NULL, #c(-1, 1),
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
position_jitter_hight = .0,
position_jitter_width = .03,
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
legend_title = "SC",
legend_x_axes_label = "x",
legend_x_position = 0.02,
legend_y_position = 0.02,
legend_h_size = 0.2,
legend_w_size = 0.2,
legend_title_size=7,
legend_number_size = 2) {
set.seed(2020)
y_axes_label = NULL
# Computing adjusted p-values with those words selected by min_freq_words = 2
word_data <- word_data[word_data$n >= min_freq_words, ]
# Select plot_n_word_extreme and Select plot_n_word_frequency
word_data_extrem_max_x <- word_data %>%
dplyr::arrange(-central_cosine) %>%
dplyr::slice(0:plot_n_word_extreme)
word_data_extrem_min_x <- word_data %>%
dplyr::arrange(central_cosine) %>%
dplyr::slice(0:plot_n_word_extreme)
word_data_frequency_x <- word_data %>%
dplyr::arrange(-n) %>%
dplyr::slice(0:plot_n_word_frequency)
# Select the middle range, order according to frequency and then select the plot_n_words_middle = 5
mean_m_sd_x <- mean(word_data$central_cosine, na.rm=TRUE) - (sd(word_data$central_cosine, na.rm=TRUE)/10) # TODO Possibility to set this one? It may be that no words comes within thi
mean_p_sd_x <- mean(word_data$central_cosine, na.rm=TRUE) + (sd(word_data$central_cosine, na.rm=TRUE)/10)
word_data_middle_x <- word_data %>%
dplyr::filter(dplyr::between(word_data$central_cosine, mean_m_sd_x, mean_p_sd_x)) %>%
dplyr::arrange(-n) %>%
dplyr::slice(0:plot_n_words_middle) # TODO selecting on frequency again. perhaps point to have exact middle?
word_data_all <- word_data %>%
dplyr::left_join(word_data_extrem_max_x %>% dplyr::transmute(words, check_extreme_max_x = 1), by = "words") %>%
dplyr::left_join(word_data_extrem_min_x %>% dplyr::transmute(words, check_extreme_min_x = 1), by = "words") %>%
dplyr::left_join(word_data_frequency_x %>% dplyr::transmute(words, check_extreme_frequency_x = 1), by = "words") %>%
dplyr::left_join(word_data_middle_x %>% dplyr::transmute(words, check_middle_x = 1), by = "words") %>%
dplyr::mutate(extremes_all_x = rowSums(cbind(check_extreme_max_x, check_extreme_min_x,
check_extreme_frequency_x, check_middle_x), na.rm = T))
# Categorise words to apply specific color
word_data_all <- word_data_all %>%
dplyr::mutate(colour_categories = dplyr::case_when(
check_extreme_min_x == 1 ~ centrality_color_codes[1],
check_middle_x == 1 ~ centrality_color_codes[2],
check_extreme_max_x == 1  ~ centrality_color_codes[3],
check_extreme_frequency_x == 1  ~ centrality_color_codes[4]
))
if(is.null(scale_x_axes_lim)){
scale_x_axes_lim <- c(min(word_data$central_cosine)-0.05, max(word_data$central_cosine)+0.05)
}
if(is.null(scale_y_axes_lim)){
scale_y_axes_lim <- c(-1, 1)
}
# This solution is because it is not possible to send "0" as a parameter
only_x_dimension <- 0
y_axes <- "only_x_dimension"
# Plot
plot <-
# construct ggplot; the !!sym( ) is to  turn the strings into symbols.
ggplot2::ggplot(data = word_data_all, ggplot2::aes(!!rlang::sym(x_axes), !!rlang::sym(y_axes), label = words)) +
ggplot2::geom_point(
data = word_data_all, # [word_data_all$extremes_all_x==0, ]
size = points_without_words_size,
alpha = points_without_words_alpha,
ggplot2::aes(color = "#EAEAEA")
) +
# ggrepel geom, make arrows transparent, color by rank, size by n
ggrepel::geom_text_repel(
data = word_data_all[word_data_all$extremes_all_x==1, ],
segment.alpha  = arrow_transparency,
position = ggplot2::position_jitter(h = position_jitter_hight, w = position_jitter_width),
ggplot2::aes(color = colour_categories, size = n, family = word_font),
) +
ggplot2::scale_color_identity() +
# Decide size and color of the points
ggplot2::geom_point(
data = word_data_all[word_data_all$extremes_all_x==1, ],
size = point_size,
ggplot2::aes(color = colour_categories)
) +
# set word size range and the guide
ggplot2::scale_size_continuous(
range = word_size_range,
guide = ggplot2::guide_legend(
title = "Frequency",
title.position = "top",
direction = "horizontal",
label.position = "bottom",
ggplot2::element_text(color = titles_color))
) +
# Title
ggplot2::ggtitle(paste0(title_top)) +
ggplot2::labs(y = y_axes_label, x = x_axes_label) +
# Help create possibility to remove y-axes numbers help(scale_y_continuous)
ggplot2::scale_x_continuous(limits = scale_x_axes_lim) +
ggplot2::scale_y_continuous(limits = scale_y_axes_lim) +
# Minimal theme, and turning off legends
ggplot2::theme_minimal() +
ggplot2::theme(
legend.position = c("bottom"),
plot.title = element_text(hjust = 0.5),
legend.justification = c("right", "top"),
panel.grid.major = ggplot2::element_blank(),
panel.grid.minor = ggplot2::element_blank(),
axis.text.y = y_axes_values,
title = ggplot2::element_text(color = titles_color),
axis.title.x = ggplot2::element_text(color = titles_color),
axis.title.y = ggplot2::element_text(color = titles_color)
)
plot
}
# Plot
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
library(tidyverse)
# Plot
centrality_plot <- textCentralityPlot(
word_data = centrality_data_harmony,
min_freq_words = 10,
plot_n_word_extreme = 10,
plot_n_word_frequency = 10,
plot_n_words_middle = 10,
titles_color = "#61605e",
x_axes = "central_cosine",
title_top = "Semantic Centrality Plot",
x_axes_label = "Semantic Centrality",
word_font = NULL,
centrality_color_codes = c("#EAEAEA","#85DB8E", "#398CF9", "#000000"),
word_size_range = c(3, 8),
point_size = 0.5,
arrow_transparency = 0.1,
points_without_words_size = 0.5,
points_without_words_alpha = 0.5,
)
centrality_plot
devtools::document()
devtools::document()
devtools::document()
devtools::document()
