words_group2_agg_single_wordembedding_f
words_group1b_freq
words_group1_single_wordembedding_b
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedStatic).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_word_embeddings)
words_group1_single_wordembedding
applysemrep
single_word_embeddings
uniques_words_all
pca_data
pca
# Pre-processing data for plotting
df_for_plotting <- textProjection(
data$harmonywords[1:5],
word_embeddings$harmonywords[1:5, ],
word_embeddings$singlewords_we,
data$hilstotal[1:5],
split = "mean",
Npermutations = 2,
n_per_split = 1,
#pca = 2
)
# Data
word_embeddings <- word_embeddings_4
data <- Language_based_assessment_data_8
# Pre-processing data for plotting
df_for_plotting <- textProjection(
data$harmonywords[1:5],
word_embeddings$harmonywords[1:5, ],
word_embeddings$singlewords_we,
data$hilstotal[1:5],
split = "mean",
Npermutations = 2,
n_per_split = 1,
#pca = 2
)
df_for_plotting
expect_true(tibble::is_tibble(df_for_plotting[[2]]))
expect_is(df_for_plotting[[2]]$words[1], "character")
expect_is(df_for_plotting[[2]]$n[1], "numeric")
single_word_embeddings
# Make dataframe (and combine x and y)
if (is.null(y)) {
x <- tibble::as_tibble_col(x)
} else {
# Combine the dimensions for for-loop
x <- tibble::tibble(x, y)
}
# Creating a list for the x and y dimensions; and one to save aggregated word embeddings and
# dot product null distributions for both x and y
# so that these can be saved and used for when manually adding words to the plot in the next step.
word_data_list <- list()
aggregated_embeddings_dot_null_distribution <- list()
# For-loop for x and y input/dimensions; i.e., y if the plot has two dimensions (i_dim=1 i_dim=2) remove(i_dim)
for (i_dim in seq_len(ncol(x))) {
# Get the word embeddings and scale/category for the plot dimension (i.e., x or y from above)
x0 <- x[i_dim]
x1 <- cbind(words, x0)
colnames(x1) <- c("words", "value")
x2 <- tibble::as_tibble(cbind(x1, word_embeddings))
############
######         1 Create COMPARISON/Projection embedding: all Group 1 & Group 2 word embeddings.
############
### Sum all word embeddings in one column
if (split == "mean" | split == "quartile") {
# split="median" split = "quartile" or create interval sensitive
if (split == "mean") {
# Splitting datasets up to low versus high according to median split
group1 <- x2 %>%
dplyr::filter(value < mean(purrr::as_vector(value), na.rm = TRUE))
group2 <- x2 %>%
dplyr::filter(value > mean(purrr::as_vector(value), na.rm = TRUE))
# Use function addEqualNrNArows from 3_1_testSimilarity
# Function adds rows of NA until group2 and group1 have the same amount of rows.
if (nrow(group1) < nrow(group2)) {
group1 <- addEqualNrNArows(group1, group2)
} else if (nrow(group1) > nrow(group2)) {
group2 <- addEqualNrNArows(group2, group1)
} else {
group1 <- group1
group2 <- group2
}
} else if (split == "quartile") {
# Select according to lower and upper quartile
# However, if it is a dichotomous variable use mean
if (length(unique(x1$value)) == 2) {
q1 <- summary(x1$value)[4][[1]]
q3 <- summary(x1$value)[4][[1]]
} else if (length(unique(x1$value)) > 2) {
q1 <- summary(x1$value)[2][[1]]
q3 <- summary(x1$value)[5][[1]]
}
group1 <- x2 %>%
dplyr::filter(x2$value <= q1, )
group2 <- x2 %>%
dplyr::filter(x2$value >= q3, )
}
## ##       Get word embeddings ####
# Group 1: getting unique words and their frequency
words_group1b_freq <- unique_freq_words(group1$words)
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words_test, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedStatic).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_word_embeddings)
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words_test, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_word_embeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
words_group1_agg_single_wordembedding_c <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group2_agg_single_wordembedding_c <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group1_agg_single_wordembedding_c <- tibble::as_tibble(words_group1_agg_single_wordembedding_c)
words_group2_agg_single_wordembedding_c <- tibble::as_tibble(words_group2_agg_single_wordembedding_c)
# Weight words for aggregated word embedding: Repeat rows according to n word_weight_power
words_group1_agg_single_wordembedding_d <- words_group1_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
words_group2_agg_single_wordembedding_d <- words_group2_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
## Get dataframe with ALL embeddings to randomly draw from (without log transformed, and quartiles)
# for Comparison distribution
words_group1_agg_single_wordembedding_e <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group1_agg_single_wordembedding_f <- words_group1_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group2_agg_single_wordembedding_e <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group2_agg_single_wordembedding_f <- words_group2_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group1_2_agg_single_wordembedding_e <- rbind(words_group1_agg_single_wordembedding_f,
words_group2_agg_single_wordembedding_f)
words_group1_2_agg_single_wordembedding_e1 <- dplyr::select(words_group1_2_agg_single_wordembedding_e,
dplyr::starts_with("Dim"))
# Interval: No split. Weighting embeddings according to interval scale.
} else if (split == "no") {
# Getting unique words and their frequency
words_group1b_freq <- unique_freq_words(x2$words)
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words_test, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Group 2
words_group2b_freq <- unique_freq_words(x2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words_test, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
# Get each words on its own row and keep value so that it can be the weight for the word embedding
words_values_sep <- x2 %>%
select(words, value) %>%
tidyr::separate_rows(words, sep = " ")
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
words_single_wordembedding <- lapply(words_values_sep$words, applysemrep, single_word_embeddings)
words_single_wordembedding_b <- dplyr::bind_rows(words_single_wordembedding)
words_single_wordembedding_c <- dplyr::bind_cols(words_values_sep, words_single_wordembedding_b)
# weight the word embeddings with the value weight
weights <- words_single_wordembedding_c$value^word_weight_power
words_single_wordembedding_d <- words_single_wordembedding_c %>%
select(-c(words, value))
words_single_wordembedding_d_scaled <- scale(words_single_wordembedding_d)
words_group2_agg_single_wordembedding_d <- tibble::as_tibble((words_single_wordembedding_d_scaled * weights) / mean(weights))
# reversed weights
weight_rev <- (max(words_single_wordembedding_c$value) + 1 - words_single_wordembedding_c$value)^word_weight_power
words_group1_agg_single_wordembedding_d <- tibble::as_tibble((words_single_wordembedding_d_scaled * weight_rev) / mean(weight_rev))
## Get dataframe with ALL embeddings to randomly draw from (without log transformed,
# and quartiles) for Comparison distribution
# Shuffle weights/values
weights_shuffled <- sample(words_single_wordembedding_c$value, replace = FALSE)
words_single_wordembedding_d_weights_shuffled <- tibble::as_tibble((words_single_wordembedding_d_scaled * weights_shuffled) /
mean(weights_shuffled))
words_group1_2_agg_single_wordembedding_e1 <- words_single_wordembedding_d_weights_shuffled
}
Aggregated_word_embedding_group1 <- textEmbeddingAggregation(dplyr::select(words_group1_agg_single_wordembedding_d,
dplyr::starts_with("Dim")), aggregation = aggregation)
Aggregated_word_embedding_group2 <- textEmbeddingAggregation(dplyr::select(words_group2_agg_single_wordembedding_d,
dplyr::starts_with("Dim")), aggregation = aggregation)
######  Project embedding ####
projected_embedding <- Aggregated_word_embedding_group2 - Aggregated_word_embedding_group1
# Position words in relation to Group 2 (High)
all_unique_words_freq <- unique_freq_words(x2$words)
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedd).
all_unique_words_we <- lapply(all_unique_words_freq$words, applysemrep, single_word_embeddings)
all_unique_words_we_b <- dplyr::bind_rows(all_unique_words_we)
if (split == "no") {
# Applying the z-score parameters to all the unique word's embeddings
scale_center_weights <- tibble::as_tibble_row(attr(words_single_wordembedding_d_scaled, "scaled:center")) %>%
slice(rep(1:dplyr::n(), each = nrow(all_unique_words_we_b)))
scale_scale_weights <- tibble::as_tibble_row(attr(words_single_wordembedding_d_scaled, "scaled:scale")) %>%
slice(rep(1:dplyr::n(), each = nrow(all_unique_words_we_b)))
all_unique_words_we_b <- tibble::as_tibble((all_unique_words_we_b - scale_center_weights) / scale_scale_weights)
}
# Position the embedding; i.e., taking the word embedding subtracted with aggregated word embedding
embedding_to_anchour_with <- tibble::as_tibble_row((Aggregated_word_embedding_group2 +
Aggregated_word_embedding_group1) / 2)
embedding_to_anchour_with <- embedding_to_anchour_with %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(all_unique_words_we_b)))
words_positioned_embeddings <- all_unique_words_we_b - embedding_to_anchour_with
# Project the embeddings using dot product.
projected_embedding_nrow <- tibble::as_tibble_row(projected_embedding) %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(all_unique_words_we_b)))
dot_products_observed <- rowSums(words_positioned_embeddings * projected_embedding_nrow)
all_unique_words_freq$dot <- dot_products_observed
# Computing the dot product projection for the aggregated and projected embeddings
all_aggregated <- dplyr::bind_rows(Aggregated_word_embedding_group1,
Aggregated_word_embedding_group2, projected_embedding)
projected_embedding_a <- tibble::as_tibble_row(projected_embedding) %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(all_aggregated)))
dot_products_all_aggregated <- rowSums(all_aggregated * projected_embedding_a)
DP_aggregate <- tibble::as_tibble_col(c("Group1*", "Group2*", "projected_embedding"), column_name = "words")
DP_aggregate$n <- c(0, 0, 0)
DP_aggregate$dot <- dot_products_all_aggregated
dot_products_observed <- c(as.vector(dot_products_all_aggregated), dot_products_observed)
# Add DP_aggregate to the words data
all_unique_words_freq <- rbind(DP_aggregate, all_unique_words_freq)
###### Comparison distributions for Project embedding ####
# Splitting up the permutations in different loops to avoid memory issues
forloops <- ceiling(Npermutations / n_per_split)
dot_null_distribution <- list()
#  i = 1
for (i in 1:forloops) {
### Create new Projected embedding
# Randomly split word embeddings into two groups: words_group1_2_agg_single_wordembedding_e1
ind <- sample(c(TRUE, FALSE), nrow(words_group1_2_agg_single_wordembedding_e1), replace = TRUE)
Aggregated_word_embedding_group1_random <- words_group1_2_agg_single_wordembedding_e1[ind, ]
Aggregated_word_embedding_group1_random <- textEmbeddingAggregation(Aggregated_word_embedding_group1_random,
aggregation = "mean")
Aggregated_word_embedding_group2_random <- words_group1_2_agg_single_wordembedding_e1[!ind, ]
Aggregated_word_embedding_group2_random <- textEmbeddingAggregation(Aggregated_word_embedding_group2_random,
aggregation = "mean")
projected_embedding_random <- Aggregated_word_embedding_group2_random - Aggregated_word_embedding_group1_random
# Select random word embeddings according to setting
indice <- sample(nrow(words_group1_2_agg_single_wordembedding_e1), n_per_split, replace = TRUE)
random_group2_embedding <- words_group1_2_agg_single_wordembedding_e1[indice, ]
# Position the embedding; i.e., taking the word embedding subtracted with aggregated word embedding
# version 1: word_new = word_old - ((group(high harmony) + group(low harmony)) / 2)
Aggregated_word_embedding_group1_long <- tibble::as_tibble_row(Aggregated_word_embedding_group1) %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(random_group2_embedding)))
Aggregated_word_embedding_group2_long <- tibble::as_tibble_row(Aggregated_word_embedding_group2) %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(random_group2_embedding)))
words_positioned_embeddings_random <- random_group2_embedding - (Aggregated_word_embedding_group2_long +
Aggregated_word_embedding_group1) / 2
# project the embeddings using dot products
projected_embedding_random_long <- tibble::as_tibble_row(projected_embedding_random) %>%
dplyr::slice(rep(1:dplyr::n(), each = nrow(words_positioned_embeddings_random)))
dot_products_null <- tibble::as_tibble(rowSums(words_positioned_embeddings_random * projected_embedding_random_long))
dot_null_distribution[i] <- dot_products_null
dot_null_distribution
}
dot_null_distribution <- tibble::as_tibble(unlist(dot_null_distribution))
### Compare observed dot-product with null
dot_null_distribution <- dot_null_distribution[stats::complete.cases(dot_null_distribution), ]
p_values_dot_prod <- purrr::map(as.list(purrr::as_vector(dot_products_observed)), p_value_comparing_with_Null,
dot_null_distribution$value,
alternative = "two_sided"
)
p_values_dot_prod <- unlist(p_values_dot_prod)
# Sort out dataframe
dot_result <- cbind(all_unique_words_freq, dot_products_observed, tibble::as_tibble(unlist(p_values_dot_prod)))
dot_result <- tibble::as_tibble(dot_result)
colnames(dot_result) <- c("words", "n", "dot", "dot2", "p_values_dot")
dot_result <- dplyr::select(dot_result, -c(dot2))
words_group2b_freq <- dplyr::select(words_group2b_freq, -c(n))
words_group1b_freq <- dplyr::select(words_group1b_freq, -c(n))
dot_result1 <- dplyr::full_join(dot_result, words_group1b_freq, by = "words")
dot_result2 <- dplyr::full_join(dot_result1, words_group2b_freq, by = "words")
dot_result <- tibble::as_tibble(dot_result2)
dot_result$n_g1_g2.y[is.na(dot_result$n_g1_g2.y)] <- 0
dot_result$n_g1_g2.x[is.na(dot_result$n_g1_g2.x)] <- 0
colnames(dot_result) <- c("words", "n", "dot", "p_values_dot", "n_g1", "n_g2")
to_be_saved_below <- list(
tibble::as_tibble_row(Aggregated_word_embedding_group1),
tibble::as_tibble_row(Aggregated_word_embedding_group2),
dot_null_distribution
)
names(to_be_saved_below) <- c(
"Aggregated_word_embedding_group1", "Aggregated_word_embedding_group2",
"dot_null_distribution"
)
# Adding the scale parameters for the word embeddings so that words can be manually added in the textProjectionPlot.
if (split == "no") {
to_be_saved_below$scale_centre <- tibble::as_tibble_row(attr(words_single_wordembedding_d_scaled, "scaled:center"))
to_be_saved_below$scale_scale <- tibble::as_tibble_row(attr(words_single_wordembedding_d_scaled, "scaled:scale"))
}
aggregated_embeddings_dot_null_distribution[i_dim] <- list(to_be_saved_below)
word_data_list[i_dim] <- list(dot_result)
}
# N_participants
N_participant_responses <- length(words)
word_embeddings <- word_embeddings_4
data <- Language_based_assessment_data_8
single_word_embeddings = word_embeddings$singlewords_we
words = data$harmonywords[1:5]
word_embeddings = word_embeddings$harmonywords[1:5, ]
x=data$hilstotal[1:5]
y = NULL
split = "mean"
Npermutations = 2
n_per_split = 1
pca = 2
min_freq_words_test = 0
word_weight_power = 1
# Description to include as a comment in the end of function
textProjection_descriptions <- paste(
"type = textProjection",
"words =", substitute(words),
"word_embeddings =", comment(word_embeddings),
"single_word_embeddings =", comment(single_word_embeddings),
"x =", substitute(x),
"y =", substitute(y),
"pca =", as.character(pca),
"aggregation = ", aggregation,
"split = ", split,
"word_weight_power =", word_weight_power,
"min_freq_words_test =", min_freq_words_test,
"Npermutations =", Npermutations,
"n_per_split =", n_per_split,
sep = " ", collapse = " "
)
aggregation = "mean"
# Description to include as a comment in the end of function
textProjection_descriptions <- paste(
"type = textProjection",
"words =", substitute(words),
"word_embeddings =", comment(word_embeddings),
"single_word_embeddings =", comment(single_word_embeddings),
"x =", substitute(x),
"y =", substitute(y),
"pca =", as.character(pca),
"aggregation = ", aggregation,
"split = ", split,
"word_weight_power =", word_weight_power,
"min_freq_words_test =", min_freq_words_test,
"Npermutations =", Npermutations,
"n_per_split =", n_per_split,
sep = " ", collapse = " "
)
set.seed(seed)
# PCA on single_word_embeddings
if (is.numeric(pca)) {
# Select word embeddings to be included in plot
uniques_words_all <- unique_freq_words(words)
uniques_words_all_wordembedding <- sapply(uniques_words_all$words, applysemrep, single_word_embeddings)
uniques_words_all_wordembedding <- tibble::as_tibble(t(uniques_words_all_wordembedding))
rec_pca <- recipes::recipe(~., data = uniques_words_all_wordembedding)
pca_trans <- rec_pca %>%
recipes::step_center(recipes::all_numeric()) %>%
recipes::step_scale(recipes::all_numeric()) %>%
recipes::step_naomit(Dim1, skip = TRUE)
if (pca < 1) {
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), threshold = pca)
} else if (pca >= 1) {
pca_trans <- recipes::step_pca(pca_trans, recipes::all_numeric(), num_comp = pca)
}
pca_estimates <- recipes::prep(pca_trans, training = uniques_words_all_wordembedding)
pca_data <- recipes::bake(pca_estimates, uniques_words_all_wordembedding)
pca_data <- pca_data %>% stats::setNames(paste0("Dim_", names(.)))
single_word_embeddings <- dplyr::bind_cols(uniques_words_all, pca_data)
single_word_embeddings
}
single_word_embeddings
# Make dataframe (and combine x and y)
if (is.null(y)) {
x <- tibble::as_tibble_col(x)
} else {
# Combine the dimensions for for-loop
x <- tibble::tibble(x, y)
}
# Creating a list for the x and y dimensions; and one to save aggregated word embeddings and
# dot product null distributions for both x and y
# so that these can be saved and used for when manually adding words to the plot in the next step.
word_data_list <- list()
aggregated_embeddings_dot_null_distribution <- list()
i_dim
# Get the word embeddings and scale/category for the plot dimension (i.e., x or y from above)
x0 <- x[i_dim]
x1 <- cbind(words, x0)
colnames(x1) <- c("words", "value")
x2 <- tibble::as_tibble(cbind(x1, word_embeddings))
x2
# Splitting datasets up to low versus high according to median split
group1 <- x2 %>%
dplyr::filter(value < mean(purrr::as_vector(value), na.rm = TRUE))
group2 <- x2 %>%
dplyr::filter(value > mean(purrr::as_vector(value), na.rm = TRUE))
# Use function addEqualNrNArows from 3_1_testSimilarity
# Function adds rows of NA until group2 and group1 have the same amount of rows.
if (nrow(group1) < nrow(group2)) {
group1 <- addEqualNrNArows(group1, group2)
} else if (nrow(group1) > nrow(group2)) {
group2 <- addEqualNrNArows(group2, group1)
} else {
group1 <- group1
group2 <- group2
}
group2
group1
group1 <- x2 %>%
dplyr::filter(x2$value <= q1, )
group2 <- x2 %>%
dplyr::filter(x2$value >= q3, )
## ##       Get word embeddings ####
# Group 1: getting unique words and their frequency
words_group1b_freq <- unique_freq_words(group1$words)
words_group1b_freq <- words_group1b_freq[words_group1b_freq$n >= min_freq_words_test, ]
words_group1b_freq$n_g1_g2 <- words_group1b_freq$n * -1
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedStatic).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_word_embeddings)
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
# Group 2
words_group2b_freq <- unique_freq_words(group2$words)
words_group2b_freq <- words_group2b_freq[words_group2b_freq$n >= min_freq_words_test, ]
words_group2b_freq$n_g1_g2 <- words_group2b_freq$n * 1
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_word_embeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
words_group1_agg_single_wordembedding_c <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group2_agg_single_wordembedding_c <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group1_agg_single_wordembedding_c <- tibble::as_tibble(words_group1_agg_single_wordembedding_c)
words_group2_agg_single_wordembedding_c <- tibble::as_tibble(words_group2_agg_single_wordembedding_c)
# Weight words for aggregated word embedding: Repeat rows according to n word_weight_power
words_group1_agg_single_wordembedding_d <- words_group1_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
words_group2_agg_single_wordembedding_d <- words_group2_agg_single_wordembedding_c %>%
dplyr::mutate(., n1 = n^word_weight_power) %>%
tidyr::uncount(n1)
## Get dataframe with ALL embeddings to randomly draw from (without log transformed, and quartiles)
# for Comparison distribution
words_group1_agg_single_wordembedding_e <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group1_agg_single_wordembedding_f <- words_group1_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group2_agg_single_wordembedding_e <- cbind(words_group2b_freq, words_group2_single_wordembedding_b)
words_group2_agg_single_wordembedding_f <- words_group2_agg_single_wordembedding_e %>%
dplyr::mutate(., n1_e = n) %>%
tidyr::uncount(n1_e)
words_group1_2_agg_single_wordembedding_e <- rbind(words_group1_agg_single_wordembedding_f,
words_group2_agg_single_wordembedding_f)
words_group1_agg_single_wordembedding_f
words_group2_agg_single_wordembedding_f
words_group1b_freq
words_group1_single_wordembedding_b
words_group2_single_wordembedding_b
words_group1_single_wordembedding_b
words_group1_single_wordembedding
words_group2_single_wordembedding
words_group2_single_wordembedding_b
words_group1_single_wordembedding_b
words_group1_single_wordembedding
words_group1b_freq$words
single_word_embeddings
# Get word embeddings for each word (applysemrep function is created in 1_1_textEmbedStatic).
words_group1_single_wordembedding <- lapply(words_group1b_freq$words, applysemrep, single_word_embeddings)
words_group1_single_wordembedding
words_group2b_freq$words
single_word_embeddings
words_group2_single_wordembedding
words_group2_single_wordembedding <- lapply(words_group2b_freq$words, applysemrep, single_word_embeddings)
words_group2_single_wordembedding_b <- dplyr::bind_rows(words_group2_single_wordembedding)
words_group2_single_wordembedding_b
words_group2_agg_single_wordembedding_c
words_group1_agg_single_wordembedding_d
words_group1_agg_single_wordembedding_c
words_group1_agg_single_wordembedding_c
words_group1_agg_single_wordembedding_c <- tibble::as_tibble(words_group1_agg_single_wordembedding_c)
words_group1_agg_single_wordembedding_c
words_group1_agg_single_wordembedding_c <- cbind(words_group1b_freq, words_group1_single_wordembedding_b)
words_group1_agg_single_wordembedding_c
words_group1b_freq
words_group1_single_wordembedding_b
words_group1_single_wordembedding_b <- dplyr::bind_rows(words_group1_single_wordembedding)
words_group1_single_wordembedding_b
words_group1_single_wordembedding
words_group1b_freq$words
words_group2b_freq$words
single_word_embeddings
pca_data <- recipes::bake(pca_estimates, uniques_words_all_wordembedding)
pca_data
seq_len(pca_data)
1:length(pca_data)
#pca_data <- pca_data %>% stats::setNames(paste0("Dim_", names(.)))
pca_data <- pca_data %>% stats::setNames(paste0("Dim", 1:length(pca_data)))
pca_data
library(text)
# Data
word_embeddings <- word_embeddings_4
data <- Language_based_assessment_data_8
# Pre-processing data for plotting
df_for_plotting <- textProjection(
data$harmonywords[1:5],
word_embeddings$harmonywords[1:5, ],
word_embeddings$singlewords_we,
data$hilstotal[1:5],
split = "mean",
Npermutations = 2,
n_per_split = 1,
pca = 2
)
df_for_plotting
library(text)
help("textTrainRegression")
help(rsample)
library(rsample)
help(validation_split)
DP_projections_HILS_SWLS_100
library(tibble)
library(dplyr)
library(testthat)
library(text)
DP_projections_HILS_SWLS_100
plot_columns <- tibble(DP_projections_HILS_SWLS_100$word_data$dot.x,
DP_projections_HILS_SWLS_100$word_data$dot.y)
plot_columns
DP_projections_HILS_SWLS_100
