options(warn=-1)  #Turn off warnings; i.e., Turning of function showing warning regarding rank deficiency since we're looking at final correlation between actual and predicted anyway. OK?
#Train and save the model; the "." takes all variables except y.
model <- train(y~., data=df3, trControl=train_control, method= methodTrain, na.action = na.omit, ...) #
models_wdifDims[[i]] <- model
options(warn=1) #Turning on warnings again
#Correlating actual with predicted values, and saving it in a list
correlations_list[[i]] <- cor.test(model$pred$pred, model$pred$obs, method=methodCor, na.action=na.omit, ...)#
}
########End of INNER cross-validation for loop
##########################
#Get t-statistics, dfs, p-values, correlation estimates and type of method from the correlations (This is not all shown in the current code, but will keep it in the code)
results_corr <- do.call("rbind", lapply(correlations_list, '[', c(1:4, 7)))
#Get strongest correlation, so that we can select the model that created it.
cor <- max(as.vector(unlist(results_corr[,"estimate"])))
#Select best model with strongest correlation by selecting which numeric position  the highest correlation is positioned in; and if several take the first as this uses fewest dimensions.
nr_model <- which(as.vector(unlist(results_corr[,"estimate"])) == max(as.vector(unlist(results_corr[,"estimate"]))))
if (length(nr_model) > 1) {
nr_model <- nr_model[1]
}else{
nr_model <- nr_model
}
#Find and save the model associated with the highest correlation, and save the correaltion result
output[[i_outer]] <- list(models_wdifDims[[nr_model]], correlations_list[results_corr[,"estimate"]==cor])
#Name the lists in the list
names(output[[i_outer]]) <- c("modelTraining", "evaluation")
help(predict)
######Predicting for the OUTER for-loop with the data not used to find what number of dimensions to use.
predicted_values[[i_outer]] <- list(as.vector(predict(output[[i_outer]]$modelTraining, newdata = df2[test_index[[i_outer]],], na.action=na.pass)))
#Saving which row indices that are connected with the predicted values so that they can be linked with actual y-values
predicted_index[[i_outer]] <- list(test_index[[i_outer]])
#Saving the actual number of dimensions used for the final predictions
semrepDims[[i_outer]] <- length(attr(terms(output[[i_outer]]$modelTraining), "term.labels"))
}
#########End of OUTER cross-validation for loop
####################################
#Arranging results from the OUTER for-loop
predicted_cv_yvalues <- unlist(do.call("cbind", lapply(predicted_values, '[')))
pred_outercv_Index <- unlist(do.call("cbind", lapply(predicted_index, '[')))
predictions <- tibble(predicted_cv_yvalues, pred_outercv_Index)
#Arrange according to index so that the actual y-values are added correctly to the dataframe
predictions <- arrange(predictions, pred_outercv_Index)
predictions$y_actual <- df2$y
#Remove indices since it has been arranged to be 1:length
predictions <- predictions %>% dplyr::select(-pred_outercv_Index)
####Arranging the results output
#Actual and predicted raw data
results[[1]] <- predictions
#Mean number of semrep dimensions used in each final prediction of the OUTER
semrepDims_v <- as.vector(unlist(do.call("cbind", lapply(semrepDims, '['))))
results[[2]] <- mean(semrepDims_v)
names(results[[2]]) <- "MeanDimensionsUsed"
#Correlation between predicted and actual values
results[[3]] <- cor.test(predictions$predicted_cv_yvalues, predictions$y_actual, method = methodCor, na.action=na.omit, ...)
results
}
#Trainging?
semantictrainingtest <- semanticTraining(solmini_norm_Semantics_space$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest
#This sets your working directory; that is, the folder that you work in.
#So on your computer, create a folder and add your raw data files in it. Then copy and past the path to the folder below.
setwd("/Users/oscar/Dropbox/Activities study 2/")
#First time you open a libray you may need to install it on your computer. So remove the # sign below and run the installation code line; then run the library line after installation. If you close down R you only need to run the library code again
#install.packages("Hmisc")
#install.packages("tidyverse")
library(tidyverse)
#Open rest of libraries (install them as needed)
#install.packages("car")
library(car)
#install.packages("psych")
library(psych)
# Load your data-file
# rad 24 är hur det såg ut i studie 1.
df <- read.csv("/Users/oscar/Dropbox/Activities study 2/Act_study_2_raw.csv", sep = ",", dec = ".", header=TRUE)
#, na.strings=c(""," ","NA")
nrow(df)
head(df)
nrow(df)
# controlling the format of date.submitted
df$submitdate
#Remove not-submitted responses; that is, remove those rows that do not have anythinig in the submitdate column
#ds[!is.na(ds$Date.submitted), ]
ds<-df[!(df$submitdate==""), ] #I just had to remove the sapce within " ".
nrow(ds)
ds$submitdate
ds$WorkerID
#Change name of the ID column to participant_id; That is, is it called ID in the dataset from limesurvey? Otherwise change "ID" below to the name it has in the ds dataframe.
colnames(ds)[which(names(ds) == "WorkerID")] <- "participant_id"
#kontrollerar participant_id
ds$participant_id
#Read Prolificdata. Rad 44 är hur det såg ut i studie 1.
#5ceb = ASDFASDFASDFAFs
#prolific_2 <- read.csv("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/August och Erik/Activities and well-being data 3/prolific_export_5de7ec7050f521766471eda8_Activities_II.csv")
prolific_1 <- read.csv("/Users/oscar/Dropbox/Activities study 2/prolific_export_5e6b54eb3ea5720f25e188e8.csv")
head(prolific_1)
nrow(prolific_1)
#kontrollerar participand_id
prolific_1$participant_id
ds$participant_id
#Merging the two files together
ds <- merge(ds, prolific_1, "participant_id")
nrow(ds)
ds
nrow(ds)
#Remove not-submitted responses; that is, remove those rows that do not have anythinig in the submitdate column
#ds[!is.na(ds$Date.submitted), ]
ds<-df[!(df$submitdate==" "), ] #I just had to remove the sapce within " ".
nrow(ds)
# Load your data-file
# rad 24 är hur det såg ut i studie 1.
df <- read.csv("/Users/oscar/Dropbox/Activities study 2/Act_study_2_raw.csv", sep = ",", dec = ".", header=TRUE)
#, na.strings=c(""," ","NA")
nrow(df)
head(df)
nrow(df)
# controlling the format of date.submitted
df$submitdate
#Remove not-submitted responses; that is, remove those rows that do not have anythinig in the submitdate column
#ds[!is.na(ds$Date.submitted), ]
ds<-df[!(df$submitdate==" "), ] #I just had to remove the sapce within " ".
nrow(ds)
df$submitdate
# Load your data-file
# rad 24 är hur det såg ut i studie 1.
df <- read.csv("/Users/oscar/Dropbox/Activities study 2/Act_study_2_raw.csv", sep = ",", dec = ".", header=TRUE)
df
#, na.strings=c(""," ","NA")
nrow(df)
head(df)
nrow(df)
# controlling the format of date.submitted
df$submitdate
df
semantictrainingtest
space_ok_300 <- space_ok_300$tk
pace_ok_300$dep_all
space_ok
solmini_min$dep_all
# Training using SE method with text space
semantictrainingtest_textspace <- semanticTraining(solmini_min$dep_all, solmini$phq_tot, Ndim = 300) #
solmini_norm$dep_all
solmini_mean$dep_all
solmini_max$dep_all
solmini_min$dep_all
solmini_norm <- textStaticSpace(solmini, space = space_ok, aggregate  = "normalize1")
semantictrainingtest_min <- semanticTraining(solmini_min_Semantics_space$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_max <- semanticTraining(solmini_max_Semantics_space$dep_all, solmini$phq_tot, Ndim = 300)
semantictrainingtest_mean <- semanticTraining(solmini_mean_Semantics_space$dep_all, solmini$phq_tot, Ndim = 300)
semantictrainingtest_norm <- semanticTraining(solmini_norm_Semantics_space$dep_all, solmini$phq_tot, Ndim = 300)
# Testing SE traingin with text space: Training using SE method with text space
semantictrainingtest_textspace_min <- semanticTraining(solmini_min$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_textspace_max <- semanticTraining(solmini_max$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_textspace_mean <- semanticTraining(solmini_mean$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_textspace_norm <- semanticTraining(solmini_norm$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_textspace
semantictrainingtest_min
semantictrainingtest_max
semantictrainingtest_mean
semantictrainingtest_norm
semantictrainingtest_textspace_min
semantictrainingtest_textspace_max
semantictrainingtest_textspace_mean
semantictrainingtest_textspace_norm
solmini_norm$dep_all
space_ok
### Function applying semreps for all character variables and saves them in a list.
##This is done because applying semreps takes time to do over and over again.
#Apply semrep to all character variables; save them as tibbles in a list; where the tibbles are called the same as the original variable
textStaticSpace <- function(df, space=space, tk_df = "tk", aggregate = "min") {
if(tk_df == "tk") {
space <- tibble::as_tibble(space$tk)
space
} else if (tk_df == "df"){
space <- tibble:as_tibble(space$df)
space
} else {
space
}
#select all character variables
df_characters <-   select_if(df, is.character)
#df_characters <- df[, sapply(df, class) == 'character']
#Create empty list
list_semrep <- list()
#For loop that apply the semrep to each character variable
for (i in 1:length(df_characters)) {
#Apply the semantic representation funtion to all rows; transpose the resulting matrix and making a tibble
list_semrep[[i]] <- as_tibble(t(sapply(df_characters[[i]], semanticrepresentation, space, aggregate)))
}
#Gives the tibbles in the list the same name as the orginal character variables
names(list_semrep) <- names(df_characters)
list_semrep
}
solmini_norm <- textStaticSpace(solmini, space = space_ok, aggregate  = "normalize1")
space_ok
solmini_norm <- textStaticSpace(solmini, space = space_ok, aggregate  = "normalize1")
space_ok
solmini_norm <- textStaticSpace(solmini, space = space_ok, tk_df = " ", aggregate  = "normalize1")
semantictrainingtest_textspace_norm <- semanticTraining(solmini_norm$dep_all, solmini$phq_tot, Ndim = 300) #
semantictrainingtest_textspace
semantictrainingtest_textspace_norm
#This sets your working directory; that is, the folder that you work in.
#So on your computer, create a folder and add your raw data files in it. Then copy and past the path to the folder below.
setwd("/Users/oscar/Dropbox/Activities study 2/")
#First time you open a libray you may need to install it on your computer. So remove the # sign below and run the installation code line; then run the library line after installation. If you close down R you only need to run the library code again
#install.packages("Hmisc")
#install.packages("tidyverse")
library(tidyverse)
#Open rest of libraries (install them as needed)
#install.packages("car")
library(car)
#install.packages("psych")
library(psych)
# Load your data-file
# rad 24 är hur det såg ut i studie 1.
df <- read.csv("/Users/oscar/Dropbox/Activities study 2/Act_study_2_raw.csv", sep = ",", dec = ".", header=TRUE)
#, na.strings=c(""," ","NA")
nrow(df)
head(df)
nrow(df)
# controlling the format of date.submitted
df$submitdate
#Remove not-submitted responses; that is, remove those rows that do not have anythinig in the submitdate column
#ds[!is.na(ds$Date.submitted), ]
ds<-df[!(df$submitdate==""), ] #I just had to remove the sapce within " ".
nrow(ds)
ds$submitdate
ds$WorkerID
#Change name of the ID column to participant_id; That is, is it called ID in the dataset from limesurvey? Otherwise change "ID" below to the name it has in the ds dataframe.
colnames(ds)[which(names(ds) == "WorkerID")] <- "participant_id"
#kontrollerar participant_id
ds$participant_id
#Read Prolificdata. Rad 44 är hur det såg ut i studie 1.
#5ceb = ASDFASDFASDFAFs
#prolific_2 <- read.csv("/Users/oscar/Desktop/Undervisning/2019 HT/handledning/August och Erik/Activities and well-being data 3/prolific_export_5de7ec7050f521766471eda8_Activities_II.csv")
prolific_1 <- read.csv("/Users/oscar/Dropbox/Activities study 2/prolific_export_5e6b54eb3ea5720f25e188e8.csv")
head(prolific_1)
nrow(prolific_1)
#kontrollerar participand_id
prolific_1$participant_id
ds$participant_id
#Merging the two files together
ds <- merge(ds, prolific_1, "participant_id")
nrow(ds)
head(ds)
ds$Control2
ds$Control
####Control questions
#First if any one is NA we give them the CORRECT answer as they did not answer the questions (i.e., if NA they have not answered it if it was a forced-answer question)
head(ds)
ds$Control[is.na(ds$Control)] <- 4
ds$Control
#Then remove those not answer correctly
ds <- ds[ds[,"Control"]==4,]
nrow(ds)
#Next control item
ds$Control2[is.na(ds$Control2)] <- 4
ds <- ds[ds[,"Control2"]==4,]
nrow(ds)
#Demographics
head(ds)
mean(ds$age)
sd(ds$age)
range(ds$age)
table(ds$Gender)
table(ds$Country.of.Birth)
order(table(ds$Country.of.Birth))
table(ds$Sex)
table(ds$Student.Status)
table(ds$Employment.Status)
ds$Socioeconomic.Status
mean(ds$Socioeconomic.Status)
sd(ds$Socioeconomic.Status)
ds$completed_date_time
ds$started_datetime
#Survey completion time (see also complettion time below) NOT FIXED
ds$started_datetime_1 <- as.POSIXct(ds$started_datetime, format="%m/%d/%Y %H:%M:%OS")
ds$started_datetime_1
help(as.POSIXct)
#Survey completion time (see also complettion time below) NOT FIXED; help(as.POSIXct)
ds$started_datetime_1 <- as.POSIXct(as.character(ds$started_datetime), format="%m/%d/%Y %H:%M:%OS")
ds$started_datetime_1
as.character(ds$started_datetime)
#Survey completion time (see also complettion time below) NOT FIXED; help(as.POSIXct)
ds$started_datetime_1 = substr(as.character(ds$started_datetime),1,nchar(as.character(ds$started_datetime))-7)
ds$started_datetime_1
ds$started_datetime_2 <- as.POSIXct(as.character(ds$started_datetime_1), format="%m/%d/%Y %H:%M")
ds$started_datetime_2
ds$started_datetime_2 <- as.POSIXct(ds$started_datetime_1, format="%Y-%m-%d %H:%M:%S")
ds$started_datetime_2
ds$completed_date_time_1 <- as.POSIXct(ds$completed_date_time, format="%Y-%m-%d %H:%M:%S:%OS")
ds$completed_date_time_1
#Total activities reflecting well-being
ds$WordsActRefWB <- paste(ds$Acitivityharmonyinsp.SQ001., ds$Acitivityharmonyinsp.SQ002., ds$Acitivityharmonyinsp.SQ003., ds$Acitivityharmonyinsp.SQ004., ds$Acitivityharmonyinsp.SQ005., sep=" ")
ds$WordsActRefWB
dput(colnames(ds))
###Activities increasing well-being
ds$WordsActIncWB <- paste(ds$Increase.SQ001., ds$Increase.SQ002., ds$Increase.SQ003., ds$Increase.SQ004., ds$Increase.SQ005., sep=" ")
ds$WordsActIncWB
dput(colnames(ds))
###Activities decreasing well-being
ds$WordsActDecWB <- paste(ds$Decrease.SQ001., ds$Decrease.SQ002., ds$Decrease.SQ003., ds$Decrease.SQ004., ds$Decrease.SQ005., sep=" ")
ds$WordsActDecWB
dput(colnames(ds))
###HIL words
ds$WordsHIL <- paste(ds$WordH.HWord1., ds$WordH.HWord2., ds$WordH.HWord3., ds$WordH.HWord4., ds$WordH.HWord5., sep=" ")
ds$WordsHIL
dput(colnames(ds))
###SWL words
ds$WordsSWL <- paste(ds$WordS.HWord1., ds$WordS.HWord2., ds$WordS.HWord3., ds$WordS.HWord4., ds$WordS.HWord5., sep=" ")
ds$WordsSWL
dput(colnames(ds))
#Create own dataframe containing all items for a rating scales in order to check alpha and omega
head(ds)
#Merge condition 1 and 2 columns (i.e., who answered HILS versus SWLS first)
ds$HILS1[!is.na(ds$HILS12)] = ds$HILS12[!is.na(ds$HILS12)]  # merge those answering HILS-3 first and last
ds$HILS2[!is.na(ds$HILS22)] = ds$HILS22[!is.na(ds$HILS22)]
ds$HILS3[!is.na(ds$HILS32)] = ds$HILS32[!is.na(ds$HILS32)]
ds$SWLS1[!is.na(ds$SWLS11)] = ds$SWLS11[!is.na(ds$SWLS11)]
ds$SWLS2[!is.na(ds$SWLS21)] = ds$SWLS21[!is.na(ds$SWLS21)]
ds$SWLS3[!is.na(ds$SWLS31)] = ds$SWLS31[!is.na(ds$SWLS31)]
hils_tot_frame <- data.frame(ds$HILS1, ds$HILS2, ds$HILS3)
hils_tot_frame
alpha(hils_tot_frame)
omega(hils_tot_frame)
#install.packages("GPArotation")
#Add rating scale to the dataframe called ds
ds$hils_3_total <- c(ds$HILS1 + ds$HILS2 + ds$HILS3)
#Look at the rating scale
library(psych)
psych::describe(ds$hils_3_total)
hist(ds$hils_3_total)
SWLS_tot_frame <- data.frame(ds$SWLS1, ds$SWLS2, ds$SWLS3)
SWLS_tot_frame
alpha(SWLS_tot_frame)
omega(SWLS_tot_frame)
#Add rating scale to the dataframe called ds
ds$SWLS_3_total <- c(ds$SWLS1 + ds$SWLS2 + ds$SWLS3)
#Look at the rating scale
library(psych)
psych::describe(ds$SWLS_3_total)
hist(ds$SWLS_3_total)
head(ds)
PA_tot_frame <- data.frame(ds$PANAS1, ds$PANAS3, ds$PANAS5, ds$PANAS9, ds$PANAS10, ds$PANAS12, ds$PANAS14, ds$PANAS16, ds$PANAS17, ds$PANAS19)
PA_tot_frame
alpha(PA_tot_frame)
omega(PA_tot_frame)
#Add rating scale to the dataframe called ds
ds$PA_10_total <- c(ds$PANAS1 + ds$PANAS3 + ds$PANAS5 + ds$PANAS9 + ds$PANAS10 + ds$PANAS12 + ds$PANAS14 + ds$PANAS16 + ds$PANAS17 + ds$PANAS19)
#Look at the rating scale
library(psych)
psych::describe(ds$PA_10_total)
hist(ds$PA_10_total)
NA_tot_frame <- data.frame(ds$PANAS2, ds$PANAS4, ds$PANAS6, ds$PANAS7, ds$PANAS8, ds$PANAS11, ds$PANAS13, ds$PANAS15, ds$PANAS18, ds$PANAS20)
NA_tot_frame
alpha(NA_tot_frame)
omega(NA_tot_frame)
#Add rating scale to the dataframe called ds
ds$NA_10_total <- c(ds$PANAS2 + ds$PANAS4 + ds$PANAS6 + ds$PANAS7 + ds$PANAS8 + ds$PANAS11 + ds$PANAS13 + ds$PANAS15 + ds$PANAS18 + ds$PANAS20)
#Look at the rating scale
library(psych)
psych::describe(ds$NA_10_total)
hist(ds$NA_10_total)
NA_tot_frame <- data.frame(ds$PANAS2, ds$PANAS4, ds$PANAS6, ds$PANAS7, ds$PANAS8, ds$PANAS11, ds$PANAS13, ds$PANAS15, ds$PANAS18, ds$PANAS20)
NA_tot_frame
alpha(NA_tot_frame)
omega(NA_tot_frame)
#Correlation between two variables
cor.test(ds$hils_3_total, ds$SWLS_3_total, method = "spearman")
#Function to correlate many items and creat "significance-stars"; note that you can change in TWO places in the function for spearman eller pearson etc
library(Hmisc)
corstarsl <- function(x){
require(Hmisc)
x <- as.matrix(x)
R <- rcorr(x, type="pearson")$r
p <- rcorr(x, type="pearson")$P
## define notions for significance levels; spacing is important.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
## trunctuate the matrix that holds the correlations to two decimal
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
## build a new matrix that includes the correlations with their apropriate stars
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
## remove upper triangle (Original)
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- NA
Rnew <- as.data.frame(Rnew)
## remove last column and return the matrix (which is now a data frame)
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Create a dataframe with all the rating scales that you want to include in the correlation table
correlationtable <- data.frame(ds$hils_3_total, ds$SWLS_3_total, ds$PA_10_total, ds$NA_10_total)
##Create table _insert your dataframe below
New_tableP<-corstarsl(correlationtable)
New_tableP
#Number particiants
nrow(correlationtable)
#Save correlation table in your working directory so that you can copy and past it into a table in word or Excel
write.csv(New_tableP, "Correlation_table_study_2_test.csv")
#Dsciding which columns to save for a file to insert to another program such as Semantic Excel; can skip this step and just write ds instead of ds_all below
#Consider starting with all the text-variables first and then the rating scale total scores for the file to be imported to Semantic Excel
#Get column names that can be copied in to the like below
dput(names(ds))
#Creat dataframe
ds_all <- ds[, c("ThinkSatisfaction_all", "hils_3_total", "participant_id", "id",
"startlanguage", "startdate", "datestamp", "condition", "thinksatisfaction_createJS1",
"thinksatisfaction_createJS2", "thinksatisfaction_createJS3",
"thinksatisfaction_createJS4", "thinksatisfaction_createJS5",
"thinkdissatisfaction_createJDS1", "thinkdissatisfaction_createJDS2",
"thinkdissatisfaction_createJDS3", "thinkdissatisfaction_createJDS4",
"thinkdissatisfaction_createJDS5", "thinkofjob_ThinkJob1", "thinkofjob_ThinkJob2",
"thinkofjob_ThinkJob3", "thinkofjob_ThinkJob4", "thinkofjob_ThinkJob5",
"Jobsatisfaction_YourJS1", "Jobsatisfaction_YourJS2", "Jobsatisfaction_YourJS3",
"Jobsatisfaction_YourJS4", "Jobsatisfaction_YourJS5", "HILS1",
"HILS2", "HILS3", "SWLS1", "SWLS2", "SWLS3", "Control", "SWLS11",
"SWLS21", "SWLS31", "HILS12", "HILS22", "HILS32", "Control2",
"Recognition", "Close", "Good", "Secure", "Management", "Physhealth",
"Wages", "Talents", "Supervisors", "Feelgood", "session_id",
"status", "started_datetime", "completed_date_time", "time_taken",
"age", "num_approvals", "num_rejections", "prolific_score", "reviewed_at_datetime",
"entered_code", "Employment.Status", "First.Language", "Nationality",
"Gender.identity", "Student.Status", "Country.of.Birth", "Sex",
"Current.Country.of.Residence", "startdate_1", "submitdate_1",
"time_Dif")]
ds_all
#Install these packages (might work without Rtools);
#install.packages("Rtools")
#install.packages(c('devtools', 'dplyr', 'tokenizers', 'caret', 'tidyr', 'BSDA', 'ggrepel', 'rio'))
#install_version("psych", version == "1.8.10", repos="http://cran.us.r-project.org")
library(devtools)
#Öppna bibliotek; om ngt inte funkar kör install.packages(NAME_OF_PACKAGE)
library(text)
library(tibble)
# Select the relevant  variables from your datafram called ds
ds_activitiesTwo <- ds[,c("WordsActRefWB", "WordsActIncWB", "WordsActDecWB", "WordsHIL", "WordsSWL",
"hils_3_total", "SWLS_3_total", "PA_10_total", "NA_10_total")]
ds_activitiesTwo
#show the variables
ds_activitiesTwo
#Check the number of rows (i.e., number of participants)
nrow(ds_activitiesTwo)
#transforming to tibble format, easier for the computer. You don't have to care.
ds_activitiesTwo <- as_tibble(ds_activitiesTwo)
#show variables in tibble mode
ds_activitiesTwo
# Selecting complete rows only (i.e., remove rows with NA in them)
ds_activitiesTwo_no_na <- ds_activitiesTwo[complete.cases(ds_activitiesTwo), ]
# see how many complete rows there was (should be 284)
nrow(ds_activitiesTwo_no_na)
ds_activitiesTwo_no_na
#transforming words to wordembeddings (a form of semantic representation), for all rows.
# wordembeddingsActivitiesTwo <- textImport(ds_activitiesTwo_no_na)
#visualising the wordembeddings
wordembeddingsActivitiesTwo
# Get the word embeddings again
wordembeddingsActivitiesTwo <- readRDS("/Users/oscar/Dropbox/Activities study 2/wordembeddingsTwo.rds")
wordembeddingsActivitiesTwo
#checkar att vi har wordembeddings för dessa variabler
wordembeddingsActivitiesTwo$WordsActRefWB
#om man behöver hjälp så kan man slå in denna
help("textTrain")
# Get word embeddings for word norms from a free online library
word_norms_embeddings <- readRDS(url("https://oscarkjell.se/text_models/semsim_Word_Norms_Mental_Health_Kjell2018.rda"))
### harmony semantic similarity scores
# Compute semantic similarity score between the harmony answers and the harmony norm
norm_similarity_scores_harmony <- textSimilarityNorm(wordembeddingsActivitiesTwo$WordsHIL,
word_norms_embeddings$harmonynorm)
# Correlating the semantic measure with the corresponding rating scale
psych::corr.test(norm_similarity_scores_harmony, ds_activitiesTwo_no_na$hils_3_total)
# Compute semantic similarity score between the harmony answers and the harmony norm
norm_similarity_scores_disharmony <- textSimilarityNorm(wordembeddingsActivitiesTwo$WordsHIL,
word_norms_embeddings$disharmonynorm)
# Correlating the semantic measure with the corresponding rating scale
psych::corr.test(norm_similarity_scores_disharmony, ds_activitiesTwo_no_na$hils_3_total)
# bipolar semantic similarity score between HIL words and harmony-disharmony norms
bipolar_sss_HIL <- norm_similarity_scores_harmony - norm_similarity_scores_disharmony
# training ActRefWB words to unipolar SSS HIL
ActRefWB_USSSHIL <- textTrain(wordembeddingsActivitiesTwo$WordsActRefWB, norm_similarity_scores_harmony)
ActRefWB_USSSHIL$Correlation
# training ActRefWB words to bipolar SSS HIL
ActRefWB_BSSSHIL <- textTrain(wordembeddingsActivitiesTwo$WordsActRefWB, bipolar_sss_HIL)
bipolar_sss_HIL
norm_similarity_scores_harmony
norm_similarity_scores_disharmony
# bipolar semantic similarity score between HIL words and harmony-disharmony norms
bipolar_sss_HIL <- norm_similarity_scores_harmony - norm_similarity_scores_disharmony
bipolar_sss_HIL
### satisfaction semantic similarity scores
# Compute semantic similarity score between the satisfaction answers and the satisfaction norm
norm_similarity_scores_satisfaction <- textSimilarityNorm(wordembeddingsActivitiesTwo$WordsSWL,
word_norms_embeddings$satisfactionnorm)
# Correlating the semantic measure with the corresponding rating scale
psych::corr.test(norm_similarity_scores_satisfaction, ds_activitiesTwo_no_na$SWLS_3_total)
# Compute semantic similarity score between the satisfaction answers and the dissatisfaction norm
norm_similarity_scores_dissatisfaction <- textSimilarityNorm(wordembeddingsActivitiesTwo$WordsSWL,
word_norms_embeddings$dissatisfactionnorm)
# Correlating the semantic measure with the corresponding rating scale
psych::corr.test(norm_similarity_scores_dissatisfaction, ds_activitiesTwo_no_na$SWLS_3_total)
# bipolar semantic similarity score between SWL words and Satisfaction-dissatisafaction norms
bipolar_sss_SWL <- norm_similarity_scores_satisfaction - norm_similarity_scores_dissatisfaction
bipolar_sss_SWL
# training ActRefWB words to unipolar SSS SWL
ActRefWB_USSSSWL <- textTrain(wordembeddingsActivitiesTwo$WordsActRefWB, norm_similarity_scores_satisfaction)
norm_activities_increaing_wb <- paste(wordembeddingsActivitiesTwo$WordsActIncWB, collapse = ' ')
norm_activities_increaing_wb
wordembeddingsActivitiesTwo$WordsActIncWB
wordembeddingsActivitiesTwo$WordsActRefWB
norm_activities_increaing_wb
dtm
# Get the "feature in document" co-occurrence matrix
dtm_ok <- t(dtm) %*% dtm
