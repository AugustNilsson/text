% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/1_1_textEmbed.R
\name{textEmbed}
\alias{textEmbed}
\title{Extract layers and aggregate them to word embeddings, for all character variables in the dataframe.}
\usage{
textEmbed(
  x,
  pretrained_weights = "bert-base-uncased",
  tokenizer_class = BertTokenizer,
  model_class = BertModel,
  contexts = TRUE,
  layers = 11:12,
  context_aggregation = "mean",
  context_tokens_select = NULL,
  context_tokens_deselect = NULL,
  decontexts = TRUE,
  decontext_layers = 11:12,
  decontext_aggregation = "mean",
  decontext_tokens_select = NULL,
  decontext_tokens_deselect = NULL
)
}
\arguments{
\item{x}{Tibble/dataframe with at least one character variable.}

\item{pretrained_weights}{Character specifying pre-trained language model (default 'bert-base-uncased'). For an up-to-date
list of avaiable models see https://github.com/huggingface/transformers.}

\item{tokenizer_class}{Tokenizer that match pretrained_weights (default BertTokenizer). For an up-to-date
list of avaiable models see https://github.com/huggingface/transformers.}

\item{model_class}{Model class that matches pretrained_weights and tokenizer_class (default BertModel). For an up-to-date
list of avaiable models see https://github.com/huggingface/transformers.}

\item{contexts}{Provide word embeddings based on word contexts (standard method; default = TRUE).}

\item{layers}{Specify the layers that should be extracted (default 'all'). It is more efficient to only extract the layers
that you need (e.g., 11:12). Layer 0 is the decontextualised input layer (i.e., not comprising hidden states) and thus adviced to not use.
These layers can then be aggregated in the textLayerAggregation function.}

\item{context_aggregation}{Method to aggregate the contextualised layers (e.g., "mean", "min" or "max).}

\item{context_tokens_select}{Option to select word embeddings linked to specific tokens such as [CLS] and [SEP] for the context embeddings.}

\item{context_tokens_deselect}{Option to deselect embeddings linked to specific tokens such as [CLS] and [SEP] for the context embeddings.}

\item{decontexts}{Provide word embeddings of single words as input (embeddings used for plotting; default = TRUE).}

\item{decontext_layers}{Layers to aggregate for the decontext embeddings.}

\item{decontext_aggregation}{Method to aggregate the decontextualised layers (i.e., embeddings from single words; e.g., "mean", "min" or "max).}

\item{decontext_tokens_select}{Option to select embeddings linked to specific tokens such as [CLS] and [SEP] for the decontext embeddings.}

\item{decontext_tokens_deselect}{option to deselect embeddings linked to specifc tokens such as [CLS] and [SEP] for the decontext embeddings.}
}
\value{
A tibble with tokens, layer identifyer and word embeddings. Note that layer 0 is the input embedding to the transformer
}
\description{
Extract layers and aggregate them to word embeddings, for all character variables in the dataframe.
}
\examples{
\dontrun{
x <- Language_based_assessment_data_8_10[1:2, 1:2]
wordembeddings <- textEmbed(x, layers = 'all')
}
}
\seealso{
see \code{\link{textLayerAggregation}} and \code{\link{textHuggingFace}}
}
