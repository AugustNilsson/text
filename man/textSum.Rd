% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/5_4_textSum.R
\name{textSum}
\alias{textSum}
\title{Summarize text such as news articles.}
\usage{
textSum(
  x,
  model = "",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "warning",
  return_incorrect_results = FALSE,
  return_text = TRUE,
  return_tensors = FALSE,
  clean_up_tokenization_spaces = FALSE
)
}
\arguments{
\item{x}{(string)  A character variable or a tibble/dataframe with at least one character variable.}

\item{model}{(string)  Specify a pre-trained language model that have been fine-tuned on a summarization task,
such as ’bart-large-cnn’, ’t5-small’, ’t5-base’, ’t5-large’, ’t5-3b’, ’t5-11b’.}

\item{device}{(string)  Name of device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number}

\item{tokenizer_parallelism}{(boolean)  If TRUE this will turn on tokenizer parallelism. Default FALSE.}

\item{logging_level}{(string)  Set the logging level. Default: "warning".
Options (ordered from less logging to more logging): critical, error, warning, info, debug}

\item{return_incorrect_results}{(boolean)  Many models are not created to be able to provide classifications - this setting
stops them from returning incorrect results.}

\item{return_text}{(boolean)  Whether or not the outputs should include the decoded text.}

\item{return_tensors}{(boolean)  Whether or not the output should include the prediction tensors (as token indices).}

\item{clean_up_tokenization_spaces}{(boolean)  Option to clean up the potential extra spaces in the returned text.}
}
\value{
A tibble with.
}
\description{
Summarize text such as news articles.
}
\examples{
\donttest{
sum_example <- textSum("The meaning of life is")
}
}
\seealso{
see \code{\link{textEmbedLayerAggregation}} and \code{\link{textEmbed}}
}
